{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3491,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "In the previous modules, the LHS Parser received an LHS string, describing some graph pattern, and parsed it to an equivalent NetworkX DiGraph. In the following module, we search for **matches** to this pattern in our input graph - That is, find all subgraphs of our input graph, which have the same structure as the pattern in terms of nodes, the edges connecting them and the attributes they all have. \n",
    "\n",
    "Each match is basically a mapping from a subset of the input graph nodes to a the pattern nodes (as we can deduce what are the matched edges and attributes accordingly).\n",
    "\n",
    "The **Matcher** in this module does the following:\n",
    "* **Searches for matches** in the input graph, according to some LHS pattern graph.\n",
    "* **Filters matches** based on an explicit boolean function, and / or constraints given to the matcher by the parser to be handled later.\n",
    "* **Constructs a list of Match objects**, each corresponds to one of the filtered matches we've found. The list will be used in later modules, and will also allow users to view the matches and to use them imperatively.\n",
    "\n",
    "The final, filtered list of Match objects is returned from this module's main function, **find_matches**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3493,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import *\n",
    "from networkx import DiGraph\n",
    "from networkx.algorithms import isomorphism # check subgraph's isom.\n",
    "from graph_rewrite.core import NodeName, _create_graph, draw\n",
    "from graph_rewrite.lhs import lhs_to_graph\n",
    "from graph_rewrite.match_class import Match, mapping_to_match, is_anonymous_node,draw_match\n",
    "from itertools import product, permutations\n",
    "from typing import Tuple, Iterator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Matches\n",
    "Given an input graph and a pattern graph, we want to find the list of matches from pattern nodes to input-graph nodes, each constructs a corresponding Match object. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Attribute Existence and Constant Values\n",
    "A crucial aspect of finding matches is comparing the attributes of nodes to determine whether they are compatible. Nodes that match based on either the existence of specific attributes or constant attribute values are considered candidates. These candidates are then further refined to identify all valid matches for the given pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3494,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# TODO: Ensure we separate between constant attributes and existence checks (constants).\n",
    "# a[id] -> existence check (can be checked before combinatorics)\n",
    "# a[id=Constant(3)] -> constant value check (can be checked before combinatorics)\n",
    "\n",
    "# TODO: Email Dean regarding the parser ability to support constant values in the pattern graph - it is currently not supported, and so all constant values will still\n",
    "#  result in a None value in the pattern graph.\n",
    "class Constant:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "\n",
    "def _attributes_match(pattern_attrs: dict, input_attrs: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the input attributes match the pattern attributes.\n",
    "\n",
    "    This function supports both:\n",
    "    - Existence checks (ensures that required attributes exist).\n",
    "    - Constant value checks (ensures that constant values match).\n",
    "\n",
    "    Args:\n",
    "        pattern_attrs (dict): Attributes of the pattern (node or edge).\n",
    "        input_attrs (dict): Attributes of the input (node or edge).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the input attributes match the pattern attributes, False otherwise.\n",
    "    \"\"\"\n",
    "    for attr_name, attr_value in pattern_attrs.items():\n",
    "        if attr_name not in input_attrs:  # If the attribute does not exist, return False\n",
    "            return False\n",
    "        \n",
    "        if attr_value is None: # If the attribute exists, but the value is None, continue to the next attribute\n",
    "            continue\n",
    "\n",
    "        # TODO: This is not supported yet due to the parser not supporting constant values in the pattern graph - we will never reach this point, and it is implemented for future use, \n",
    "        # once the parser supports it.\n",
    "        if isinstance(attr_value, Constant):  # If the attribute exists, and the value is a constant, check if the value matches\n",
    "            if input_attrs[attr_name] != attr_value.value:\n",
    "                return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Narrow Down Search Space\n",
    "Using the functions presented thus far, the search for matches might take a lot of time if the graph has a high number of nodes / edges. Nodes which are no real candidate to match any pattern node (do not share attributes with any pattern node) are checked eitherway, which is extermely inefficient. \n",
    "\n",
    "Therefore, before we search for matches in our input graph, we will reduce it to only contain the nodes that might match any of the pattern nodes (and their connected edges as well). This might improve the whole matching performance. The following function is used in order to do single nodesly that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3495,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _find_input_nodes_candidates(pattern_node: NodeName, pattern: DiGraph, input_graph: DiGraph) -> set[NodeName]:\n",
    "    \"\"\"\n",
    "    Given a pattern node and an input graph, return a set of input graph nodes that:\n",
    "    - Contain the required attributes of the pattern node, including constant value checks (if specified) and existence checks (if no value is specified / no constant value).\n",
    "    - Have at least one edge with matching attributes for each edge of the pattern node that has attributes specified.\n",
    "\n",
    "    Args:\n",
    "        pattern_node (NodeName): The pattern node.\n",
    "        pattern (DiGraph): The pattern graph.\n",
    "        input_graph (DiGraph): The input graph.\n",
    "\n",
    "    Returns:\n",
    "        set[NodeName]: A set of input graph nodes that match the required attributes and have at least one matching edge.\n",
    "    \"\"\"\n",
    "\n",
    "    pattern_node_attrs = pattern.nodes[pattern_node]\n",
    "\n",
    "    if \"_id\" in pattern_node_attrs:\n",
    "        input_node_id = pattern_node_attrs.pop(\"_id\")\n",
    "        input_nodes_to_check = [input_node_id]\n",
    "    else:\n",
    "        input_nodes_to_check = list(input_graph.nodes)\n",
    "\n",
    "    # Filter nodes by attributes first\n",
    "    candidate_nodes = {\n",
    "        input_node\n",
    "        for input_node in input_nodes_to_check\n",
    "        if _attributes_match(pattern_node_attrs, input_graph.nodes[input_node])\n",
    "    }\n",
    "\n",
    "    return candidate_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Helper function to check if an input edge matches the pattern edge\n",
    "def _is_valid_edge_candidate(input_graph: DiGraph, pattern_edge_attrs: dict, \n",
    "                   src_candidate: NodeName, dst_candidate: NodeName, \n",
    "                   src_pattern_node: NodeName, dst_pattern_node: NodeName) -> bool:\n",
    "    \"\"\"\n",
    "    Check if an edge between two input nodes matches the pattern edge and attributes.\n",
    "\n",
    "    Args:\n",
    "        input_graph (DiGraph): The input graph.\n",
    "        pattern_edge_attrs (dict): Attributes of the pattern edge to match.\n",
    "        src_candidate (NodeName): The source candidate node in the input graph.\n",
    "        dst_candidate (NodeName): The destination candidate node in the input graph.\n",
    "        src_pattern_node (NodeName): The source pattern node.\n",
    "        dst_pattern_node (NodeName): The destination pattern node.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the input edge is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    if (src_candidate, dst_candidate) not in input_graph.edges:\n",
    "        return False\n",
    "\n",
    "    input_edge_attrs = input_graph.get_edge_data(src_candidate, dst_candidate, default={})\n",
    "    if not _attributes_match(pattern_edge_attrs, input_edge_attrs):\n",
    "        return False\n",
    "\n",
    "    # Special case: If the source and destination are the same node in the pattern,\n",
    "    # ensure the source and destination candidates are also the same in the input graph\n",
    "    if src_pattern_node == dst_pattern_node and src_candidate != dst_candidate:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3497,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _filter_edge_candidates(input_graph: DiGraph, pattern: DiGraph, \n",
    "                            src_pattern_node: NodeName, dst_pattern_node: NodeName, \n",
    "                            src_candidates: Set[NodeName], dst_candidates: Set[NodeName]) -> Set[Tuple[NodeName, NodeName]]:\n",
    "    \"\"\"\n",
    "    Filter the input node candidates for two pattern nodes by checking if the edges between them in the input graph exist\n",
    "    and match the pattern edge attributes.\n",
    "\n",
    "    Args:\n",
    "        input_graph (DiGraph): The input graph.\n",
    "        pattern (DiGraph): The pattern graph (provides the edge attributes).\n",
    "        src_pattern_node (NodeName): The source pattern node.\n",
    "        dst_pattern_node (NodeName): The destination pattern node.\n",
    "        src_candidates (Set[NodeName]): Current candidates for the source pattern node.\n",
    "        dst_candidates (Set[NodeName]): Current candidates for the destination pattern node.\n",
    "\n",
    "    Returns:\n",
    "        Set[Tuple[NodeName, NodeName]]: A set of valid candidate edge assignments (source, destination).\n",
    "    \"\"\"\n",
    "\n",
    "    pattern_edge_attrs = pattern.get_edge_data(src_pattern_node, dst_pattern_node, default={})\n",
    "\n",
    "    valid_edge_candidates = {\n",
    "        (src_candidate, dst_candidate)\n",
    "        for src_candidate, dst_candidate in product(src_candidates, dst_candidates)\n",
    "        if _is_valid_edge_candidate(input_graph, pattern_edge_attrs, src_candidate, dst_candidate, src_pattern_node, dst_pattern_node)\n",
    "    }\n",
    "\n",
    "    return valid_edge_candidates\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Pattern Based Matches\n",
    "NetworkX provides an out-of-the-box isomorphism matcher, which compares the structure of two graphs and tells whether they are isomorphic (have the same nodes and edges). We utilize this isomorphism matcher by beginning our matching process with structural matches, after filtering out candidates that do not match based on existance of attributes or constant values of attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3498,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _extend_assignments_with_nodes(pattern_nodes_mapped_to_candidates, partial_assignments: List[Dict[NodeName, NodeName]], input_graph: DiGraph) -> List[Dict[NodeName, NodeName]]:\n",
    "    \"\"\"\n",
    "    Extend the partial assignments with nodes that have not been assigned yet, ensuring that each input node is only\n",
    "    assigned once across the assignment, while respecting the filtered candidates for each pattern node.\n",
    "\n",
    "    Args:\n",
    "        pattern_nodes_mapped_to_candidates (Dict[NodeName, Set[NodeName]]): Dictionary mapping each unassigned pattern node \n",
    "                                                                            to its set of candidate input nodes.\n",
    "        partial_assignments (List[Dict[NodeName, NodeName]]): List of current partial assignments.\n",
    "        input_graph (DiGraph): The input graph.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[NodeName, NodeName]]: The partial assignments extended with nodes.\n",
    "    \"\"\"\n",
    "    extended_assignments = []\n",
    "\n",
    "    for partial_assignment in partial_assignments:\n",
    "        unused_input_nodes = set(input_graph.nodes) - set(partial_assignment.values())\n",
    "        filtered_candidates = {}\n",
    "        for pattern_node, candidates in pattern_nodes_mapped_to_candidates.items():\n",
    "            filtered_candidates[pattern_node] = candidates & unused_input_nodes\n",
    "\n",
    "        current_assignments = [partial_assignment]\n",
    "\n",
    "        # Iterate over each unassigned pattern node and extand the current partial_assignment to multiple partial assignments\n",
    "        # where each one has a different candidate for this node\n",
    "        for pattern_node in filtered_candidates.keys():\n",
    "            new_assignments = []\n",
    "            for assignment in current_assignments:\n",
    "                # Ensure uniqueness by finding unused candidates for the current node\n",
    "                unused_candidates = unused_input_nodes - set(assignment.values())\n",
    "                possible_candidates = filtered_candidates[pattern_node] & unused_candidates\n",
    "                # Extend assignment with all possible candidates\n",
    "                for candidate in possible_candidates:\n",
    "                    new_assignment = assignment.copy()\n",
    "                    new_assignment[pattern_node] = candidate\n",
    "                    new_assignments.append(new_assignment)\n",
    "            current_assignments = new_assignments\n",
    "\n",
    "        # Add the extended assignments for this partial assignment\n",
    "        extended_assignments.extend(current_assignments)\n",
    "\n",
    "    return extended_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _extend_assignments_with_edges(pattern_edges, partial_assignments, pattern, graph, is_self_loop=False):\n",
    "    \"\"\"\n",
    "    Extend the partial assignments with valid edge candidates.\n",
    "\n",
    "    Args:\n",
    "        pattern_edges: The edges of the pattern graph.\n",
    "        partial_assignments: The current partial assignments.\n",
    "        pattern: The pattern graph.\n",
    "        graph: The input graph.\n",
    "        is_self_loop: Whether the pattern edge is a self-loop or not.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[NodeName, NodeName]]: A list of extended assignments.\n",
    "\n",
    "    \"\"\"\n",
    "    edge_candidates = {}\n",
    "\n",
    "    if is_self_loop:\n",
    "        src_pattern_node, dst_pattern_node = pattern_edges[0]\n",
    "        src_candidates = _find_input_nodes_candidates(src_pattern_node, pattern, graph)\n",
    "        dst_candidates = src_candidates  # For self-loops, src and dst candidates are the same\n",
    "    else:\n",
    "        for src_pattern_node, dst_pattern_node in pattern_edges:\n",
    "            src_candidates = _find_input_nodes_candidates(src_pattern_node, pattern, graph)\n",
    "            dst_candidates = _find_input_nodes_candidates(dst_pattern_node, pattern, graph)\n",
    "        \n",
    "        edge_candidates[(src_pattern_node, dst_pattern_node)] = _filter_edge_candidates(\n",
    "            graph, pattern, src_pattern_node, dst_pattern_node, src_candidates, dst_candidates)\n",
    "\n",
    "    # Prepare a new list of assignments to avoid modifying the list during iteration\n",
    "    new_partial_assignments = []\n",
    "\n",
    "    # Extend assignments by iterating over valid edge candidates\n",
    "    for (src_pattern_node, dst_pattern_node) in edge_candidates.keys():        \n",
    "        for partial_assignment in partial_assignments:\n",
    "            partial_assignment_extensions = []\n",
    "            for src_candidate, dst_candidate in edge_candidates[(src_pattern_node, dst_pattern_node)]:\n",
    "                extended_assignment = _try_extending_assignment_with_edge_candidate(\n",
    "                    src_candidate, dst_candidate, partial_assignment, src_pattern_node, dst_pattern_node)\n",
    "                \n",
    "                if extended_assignment is not None and extended_assignment not in partial_assignment_extensions:\n",
    "                    partial_assignment_extensions.append(extended_assignment)\n",
    "            \n",
    "            if partial_assignment_extensions:  # Only add assignments that could be extended\n",
    "                new_partial_assignments.extend(partial_assignment_extensions)\n",
    "\n",
    "    # Return the newly created assignments with edges\n",
    "    return new_partial_assignments\n",
    "\n",
    "#| export\n",
    "def _try_extending_assignment_with_edge_candidate(src_candidate: NodeName, dst_candidate: NodeName, partial_assignment: Dict[NodeName, NodeName], \n",
    "                                            src_pattern_node: NodeName, dst_pattern_node: NodeName) -> Optional[Dict[NodeName, NodeName]]:\n",
    "    \"\"\"\n",
    "    Extend the current partial assignment by adding the given src and dst candidates, if possible.\n",
    "\n",
    "    Args:\n",
    "        src_candidate: The candidate for the source pattern node.\n",
    "        dst_candidate: The candidate for the destination pattern node.\n",
    "        partial_assignment: The current partial assignment being considered.\n",
    "        src_pattern_node: The source pattern node.\n",
    "        dst_pattern_node: The destination pattern node.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary representing the new assignment if valid, or None if it doesn't apply.\n",
    "    \"\"\"\n",
    "    new_assignment = partial_assignment.copy()\n",
    "    assigned_pattern_nodes = set(new_assignment.keys())\n",
    "    used_candidates = set(new_assignment.values())\n",
    "\n",
    "    # Check if the source and destination nodes are already assigned to different nodes\n",
    "    if src_pattern_node in assigned_pattern_nodes and new_assignment[src_pattern_node] != src_candidate:\n",
    "        return None\n",
    "\n",
    "    if dst_pattern_node in assigned_pattern_nodes and new_assignment[dst_pattern_node] != dst_candidate:\n",
    "        return None\n",
    "\n",
    "    # Handle self-loop edges\n",
    "    if src_pattern_node == dst_pattern_node:\n",
    "        if src_candidate == dst_candidate:\n",
    "            new_assignment[src_pattern_node] = src_candidate\n",
    "            return new_assignment\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # The edge is not a self-loop, so src and dst candidates must be different\n",
    "    if src_candidate == dst_candidate:\n",
    "        return None\n",
    "\n",
    "    # Case 1: Both src and dst nodes are not assigned, and the candidates are not used, assign them\n",
    "    if src_pattern_node not in assigned_pattern_nodes and dst_pattern_node not in assigned_pattern_nodes:\n",
    "        if src_candidate not in used_candidates and dst_candidate not in used_candidates:\n",
    "            new_assignment[src_pattern_node] = src_candidate\n",
    "            new_assignment[dst_pattern_node] = dst_candidate\n",
    "            return new_assignment\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Case 2: If the pattern src node is assigned with the input src candidate, but the dst node is not assigned, \n",
    "    # and the dst candidate is not used, assign them\n",
    "    if src_pattern_node in assigned_pattern_nodes and new_assignment[src_pattern_node] == src_candidate:\n",
    "        if dst_pattern_node not in assigned_pattern_nodes and dst_candidate not in used_candidates:\n",
    "            new_assignment[dst_pattern_node] = dst_candidate\n",
    "            return new_assignment\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Case 3: If the pattern dst node is assigned with the input dst candidate, but the src node is not assigned,\n",
    "    # and the src candidate is not used, assign them\n",
    "    if dst_pattern_node in assigned_pattern_nodes and new_assignment[dst_pattern_node] == dst_candidate:\n",
    "        if src_pattern_node not in assigned_pattern_nodes and src_candidate not in used_candidates:\n",
    "            new_assignment[src_pattern_node] = src_candidate\n",
    "            return new_assignment\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    return None  # No valid assignment if none of the cases match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _find_pattern_based_matches(graph: DiGraph, pattern: DiGraph) -> Iterator[Tuple[DiGraph, Dict[NodeName, NodeName]]]:\n",
    "    \"\"\"\n",
    "    Find all subgraphs in the input graph that match the given pattern graph based on both structure (nodes and edges)\n",
    "    and attributes (existence of attributes or constant value checks).\n",
    "    \n",
    "    Args:\n",
    "        graph (DiGraph): The graph to search for matches.\n",
    "        pattern (DiGraph): The pattern graph representing the structure and attributes to match.\n",
    "    \n",
    "    Yields:\n",
    "        Iterator[Tuple[DiGraph, Dict[NodeName, NodeName]]]: Tuples of (subgraph, mapping),\n",
    "        where subgraph is the matched subgraph, and mapping is a dictionary mapping nodes in the\n",
    "        subgraph to nodes in the pattern.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate self-loops from non-self-loop edges in the pattern\n",
    "    self_loop_pattern_edges = [(src, dst) for src, dst in pattern.edges if src == dst]\n",
    "    non_self_loop_pattern_edges = [(src, dst) for src, dst in pattern.edges if src != dst]\n",
    "\n",
    "    partial_assignments = [{}]  # Initialize with an empty assignment\n",
    "\n",
    "    # Step 1: Handle self-loops first, if they exist\n",
    "    if self_loop_pattern_edges:\n",
    "        self_loop_pattern_nodes = set(src for src, _ in self_loop_pattern_edges)\n",
    "        self_loop_nodes_candidates = {node: _find_input_nodes_candidates(node, pattern, graph) for node in self_loop_pattern_nodes}\n",
    "        node_candidates_filtered_by_edge = {}\n",
    "        for pattern_node, _ in self_loop_pattern_edges:\n",
    "            node_candidates = self_loop_nodes_candidates[pattern_node]\n",
    "            node_candidates_filtered_by_edge[pattern_node] = {node for node, _ in _filter_edge_candidates(\n",
    "                graph, pattern, pattern_node, pattern_node, node_candidates, node_candidates)}\n",
    "        \n",
    "        partial_assignments = _extend_assignments_with_nodes(node_candidates_filtered_by_edge, partial_assignments, graph) or []\n",
    "\n",
    "        if not partial_assignments:  # If no valid partial assignments from self-loops, return early\n",
    "            return\n",
    "\n",
    "    # Step 2: Handle non-self-loop edges, if they exist\n",
    "    if non_self_loop_pattern_edges:\n",
    "        partial_assignments = _extend_assignments_with_edges(non_self_loop_pattern_edges, partial_assignments, pattern, graph) or []\n",
    "\n",
    "        if not partial_assignments:  # If no valid partial assignments from non-self-loop edges, return early\n",
    "            return\n",
    "\n",
    "    # Step 3: Complete the partial assignments with remaining pattern nodes (nodes without edges)\n",
    "    assignments = []\n",
    "    assigned_pattern_nodes = set()\n",
    "    for partial_assignment in partial_assignments:\n",
    "        assigned_pattern_nodes.update(partial_assignment.keys())\n",
    "        \n",
    "    remaining_pattern_nodes = set(pattern.nodes) - assigned_pattern_nodes\n",
    "\n",
    "    if not remaining_pattern_nodes:  # No remaining pattern nodes\n",
    "        assignments = partial_assignments  \n",
    "    else:\n",
    "        remaining_node_candidates = {node: _find_input_nodes_candidates(node, pattern, graph) for node in remaining_pattern_nodes}\n",
    "        assignments = _extend_assignments_with_nodes(remaining_node_candidates, partial_assignments, graph) or []\n",
    "\n",
    "    # Step 4: Yield valid subgraphs and their assignments\n",
    "    for assignment in assignments:\n",
    "        subgraph = DiGraph()\n",
    "        subgraph.add_nodes_from(set(assignment.values()))\n",
    "        for pattern_edge in list(pattern.edges):\n",
    "            graph_edge = (assignment[pattern_edge[0]], assignment[pattern_edge[1]])\n",
    "            if graph_edge in graph.edges:\n",
    "              subgraph.add_edge(graph_edge[0], graph_edge[1])\n",
    "            else: # In that case we don't need to check the rest of the isomorphism\n",
    "                break\n",
    "\n",
    "        # Validate subgraph for isomorphism\n",
    "        if isomorphism.is_isomorphic(subgraph, pattern, node_match=_attributes_match, edge_match=_attributes_match):\n",
    "            yield subgraph, assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    # We find all possible candidates for each node in the pattern, by checking the attributes of the nodes in the graph\\n    pattern_to_input_candidates = {pattern_node: _find_input_nodes_with_pattern_attributes(pattern.nodes[pattern_node], graph) for pattern_node in pattern.nodes}\\n    candidate_assignments = itertools.product(*(pattern_to_input_candidates[pattern_node] for pattern_node in list(pattern.nodes)))\\n    for assignment in candidate_assignments:\\n        # Make sure the sub_nodes are unique - we don't want to have multiple nodes in the subgraph that are mapped to the same node in the pattern\\n        if len(set(assignment)) != len(assignment): \\n            continue\\n        assignment_mapping = dict(zip(list(pattern.nodes), assignment))\\n        subg = DiGraph()\\n        subg.add_nodes_from(list(assignment))\\n        for pattern_edge in list(pattern.edges):\\n            graph_edge = (assignment_mapping[pattern_edge[0]], assignment_mapping[pattern_edge[1]])\\n            if graph_edge in graph.edges and _input_node_has_pattern_node_attributes(graph.edges[graph_edge], pattern.edges[edge]):\\n              subg.add_edge(graph_edge[0], graph_edge[1])\\n            else: # In that case we don't need to check the rest of the isomorphism\\n                break\\n                             \\n        # We only yield mappings for subgraphs that have the same amount of edges as the pattern - otherwise the subgraph won't be an isomorphism\\n        if len(subg.edges) == len(pattern.edges):\\n            yield assignment_mapping\\n\""
      ]
     },
     "execution_count": 3501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OLD    \n",
    "'''\n",
    "    # We find all possible candidates for each node in the pattern, by checking the attributes of the nodes in the graph\n",
    "    pattern_to_input_candidates = {pattern_node: _find_input_nodes_with_pattern_attributes(pattern.nodes[pattern_node], graph) for pattern_node in pattern.nodes}\n",
    "    candidate_assignments = itertools.product(*(pattern_to_input_candidates[pattern_node] for pattern_node in list(pattern.nodes)))\n",
    "    for assignment in candidate_assignments:\n",
    "        # Make sure the sub_nodes are unique - we don't want to have multiple nodes in the subgraph that are mapped to the same node in the pattern\n",
    "        if len(set(assignment)) != len(assignment): \n",
    "            continue\n",
    "        assignment_mapping = dict(zip(list(pattern.nodes), assignment))\n",
    "        subg = DiGraph()\n",
    "        subg.add_nodes_from(list(assignment))\n",
    "        for pattern_edge in list(pattern.edges):\n",
    "            graph_edge = (assignment_mapping[pattern_edge[0]], assignment_mapping[pattern_edge[1]])\n",
    "            if graph_edge in graph.edges and _input_node_has_pattern_node_attributes(graph.edges[graph_edge], pattern.edges[edge]):\n",
    "              subg.add_edge(graph_edge[0], graph_edge[1])\n",
    "            else: # In that case we don't need to check the rest of the isomorphism\n",
    "                break\n",
    "                             \n",
    "        # We only yield mappings for subgraphs that have the same amount of edges as the pattern - otherwise the subgraph won't be an isomorphism\n",
    "        if len(subg.edges) == len(pattern.edges):\n",
    "            yield assignment_mapping\n",
    "'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering Matches\n",
    "The only thing we ignored up until now is attribute values. As metioned above, the LHS Parser does not include required attribute values in the pattern graph. Instead, it constructs a boolean function which receives a Match object and checks whether the match it represents has the required attribute values (if there are any). \n",
    "\n",
    "This boolean function is further extended by the user of the library, which can pass as parameter a function of the same format, which filteres a list of Match objects based on any condition it wishes to apply. The LHS Parser, in addition to the pattern graph, provides the extended filtering function, that mixes both the user and the parser constraints which were not handled by the matcher so far.\n",
    "\n",
    "Later in this module, we will use the extended function to filter the list of Match objects we get from the structural and attribute-existence-based matchers. The signature of that function will be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "FilterFunc = Callable[[Match], bool]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting It All Togehter\n",
    "Given our ability to find matches (both structural and in terms of attribute existence) between two graphs, as well as filtering matches according to desired conditions and constraints, we can finally find complete matches of the pattern in our input graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define one last auxiliary function, which removes duplicated matches based on their mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3503,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# TODO: Not sure this is needed since we remove duplicates in the _find_pattern_based_matches function\n",
    "def _filter_duplicated_matches(matches: list[Match]) -> Iterator[Match]:\n",
    "    \"\"\"Remove duplicates from a list of Matches, based on their mappings. Return an iterator of the matches without duplications.\n",
    "\n",
    "    Args:\n",
    "        matches (list[Match]): list of Match objects\n",
    "\n",
    "    Yields:\n",
    "        Iterator[list[Match]]: Iterator of the matches without duplications.\n",
    "    \"\"\"\n",
    "\n",
    "    # We can't use a set directly because Match objects are not hashable. \n",
    "    # This is why we use a list of matche's mappings to check for duplicates.\n",
    "    mappings = []\n",
    "    for match in matches:\n",
    "        if match.mapping not in mappings:\n",
    "            mappings.append(match.mapping)\n",
    "            yield match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _find_intersecting_pattern_nodes(single_nodes_pattern: DiGraph, collection_pattern: DiGraph) -> set:\n",
    "    \"\"\"\n",
    "    Find the intersecting pattern nodes between the single nodes match pattern and the collection pattern.\n",
    "\n",
    "    The intersecting pattern nodes are those that appear in both the single nodes match pattern \n",
    "    (i.e., pattern nodes that aim to match a single, unique input node) and the collection pattern \n",
    "    (i.e., pattern nodes that aim to match multiple input nodes).\n",
    "\n",
    "    Args:\n",
    "        single_nodes_pattern (DiGraph): The pattern graph representing nodes that match single nodesly one input node.\n",
    "        collection_pattern (DiGraph): The pattern graph representing nodes that match multiple input nodes.\n",
    "\n",
    "    Returns:\n",
    "        set: A set of pattern nodes that are present in both the single nodes match pattern and the collection pattern.\n",
    "    \"\"\"\n",
    "    intersecting_pattern_nodes = set(single_nodes_pattern.nodes) & set(collection_pattern.nodes)\n",
    "    return intersecting_pattern_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _add_collections_to_single_nodes_matches(input_graph: DiGraph, collection_pattern: DiGraph, \n",
    "                                      single_nodes_matches: List[Dict[NodeName, Set[NodeName]]], intersecting_pattern_nodes: Set[NodeName]\n",
    "                                      ) -> Iterator[Dict[NodeName, Set[NodeName]]]:\n",
    "    \"\"\"\n",
    "    Add collection matches to the existing single nodes matches by finding subgraph matches for collection pattern nodes\n",
    "    and merging them with the given single nodes match mapping.\n",
    "\n",
    "    This function finds matches in the input graph that satisfy both the single nodes match pattern (pattern nodes \n",
    "    that aim to match single nodesly one input node) and the collection pattern (pattern nodes that aim to match \n",
    "    multiple input nodes).\n",
    "\n",
    "    Args:\n",
    "        input_graph (DiGraph): The input graph.\n",
    "        collection_pattern (DiGraph): The pattern graph representing nodes that match multiple input nodes.\n",
    "        single_nodes_matches (List[Dict[NodeName, Set[NodeName]]]): A list of mappings for single nodes matches, in set semantics.\n",
    "        intersecting_pattern_nodes (Set[NodeName]): A set of pattern nodes that are present in both the single nodes match pattern and the collection pattern.\n",
    "\n",
    "    Yields:\n",
    "        Iterator[Dict[NodeName, Set[NodeName]]]: An iterator over the updated mappings, where each includes both \n",
    "        the previous single nodes match mapping and the newly found collection matches for this single nodes match.\n",
    "    \"\"\"\n",
    "    input_graph_copy = input_graph.copy()\n",
    "\n",
    "    # Enrich the single nodes match mapping with the corresponding collection matches.\n",
    "    for mapping in single_nodes_matches:\n",
    "        non_intersecting_collection_pattern_nodes = set(collection_pattern.nodes) - intersecting_pattern_nodes\n",
    "        mapping.update({pattern_node: set() for pattern_node in non_intersecting_collection_pattern_nodes})\n",
    "\n",
    "        # Lock intersecting pattern nodes to their corresponding input node in the single nodes match\n",
    "        collection_pattern_copy = collection_pattern.copy()\n",
    "        for intersecting_pattern_node in intersecting_pattern_nodes:\n",
    "            collection_pattern_copy.nodes[intersecting_pattern_node]['_id'] = mapping[intersecting_pattern_node]\n",
    "\n",
    "        # Find collection matches using the locked pattern\n",
    "        collection_matches = list(_find_pattern_based_matches(input_graph_copy, collection_pattern_copy))\n",
    "\n",
    "        # Add matches for collection pattern nodes\n",
    "        for collection_match in collection_matches:\n",
    "            for collection_pattern_node, matched_input_nodes in collection_match.items():\n",
    "                if collection_pattern_node not in intersecting_pattern_nodes: # We already have the single nodes match for these nodes\n",
    "                    mapping[collection_pattern_node].add(matched_input_nodes)  # Add the matched input node\n",
    "\n",
    "        yield mapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now combining everything we saw in order to find the matches of a pattern in our input graph. The matches are returned as a (filtered) list of Match objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(input_graph: DiGraph, single_match_pattern: DiGraph, collections_pattern: DiGraph = None, \n",
    "                 condition: FilterFunc = lambda match: True) -> Iterator[Match]:\n",
    "    \"\"\"\n",
    "    Find all matches of a pattern graph in an input graph, satisfying a certain condition.\n",
    "\n",
    "    This function identifies subgraphs of the input graph that match the single match pattern \n",
    "    and the collections pattern (if provided) based on structure, attributes, and additional conditions \n",
    "    specified by the user.\n",
    "\n",
    "    Args:\n",
    "        input_graph (DiGraph): A graph where matches are searched.\n",
    "        single_match_pattern (DiGraph): The pattern graph representing single matches (nodes mapped to one input node).\n",
    "        collections_pattern (DiGraph, optional): A pattern graph representing nodes that can map to multiple input nodes. Defaults to None.\n",
    "        condition (FilterFunc, optional): A function that receives a Match object and checks if a condition holds. \n",
    "                                          Defaults to a function that always returns True.\n",
    "\n",
    "    Yields:\n",
    "        Iterator[Match]: Iterator of Match objects, each representing a match of the pattern in the input graph.\n",
    "    \"\"\"\n",
    "    # Find all single nodes matches (single node mapping) based on structure and attributes.\n",
    "    # We already inforce set semantics for the mapping, and we don't need to check for duplicates - _find_pattern_based_matches returns unique mappings.\n",
    "    mappings = [{pattern_node: {input_node} for pattern_node, input_node in mapping.items()} \n",
    "                     for _, mapping in _find_pattern_based_matches(input_graph, single_match_pattern)]\n",
    "\n",
    "    # If a collections pattern is not None, enrich single matches by adding matching collections.\n",
    "    if collections_pattern:\n",
    "        intersecting_pattern_nodes = _find_intersecting_pattern_nodes(single_match_pattern, collections_pattern)\n",
    "        mappings = _add_collections_to_single_nodes_matches(input_graph, collections_pattern, mappings, intersecting_pattern_nodes)\n",
    "\n",
    "    #TODO: we can add a member to the Match class to identify anonymous nodes, instead of checking it here\n",
    "    matches_with_filtered_versions = [\n",
    "        (\n",
    "            mapping_to_match(input_graph, single_match_pattern, collections_pattern, mapping, filter=False),\n",
    "            mapping_to_match(input_graph, single_match_pattern, collections_pattern, mapping)\n",
    "        )\n",
    "        for mapping in mappings\n",
    "    ]\n",
    "    \n",
    "    #Filter matches using the provided condition function, based on the unfiltered match.\n",
    "    filtered_matches = [filtered_match for (unfiltered_match, filtered_match) in matches_with_filtered_versions \n",
    "                        if condition(unfiltered_match)]\n",
    "\n",
    "    # Remove any duplicate matches.\n",
    "    yield from _filter_duplicated_matches(filtered_matches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assert_match(input_graph: DiGraph, LHS: str, expected: list[dict], condition=lambda x: True, plot=True):\n",
    "    \"\"\"Match the pattern in the input graph, and validate that the list of matches\n",
    "    is equal to the expected list of matches. Also allows plotting the first match instance.\n",
    "\n",
    "    Args:\n",
    "        input_graph (DiGraph): The input graph where matches are searched.\n",
    "        LHS (str): The pattern string to be converted into a pattern graph.\n",
    "        expected (list[dict]): The expected matches (as mappings from pattern nodes to input graph nodes).\n",
    "        condition (callable, optional): A function that receives a Match object and checks if a condition holds. Defaults to True.\n",
    "        plot (bool, optional): If True, plots the first match instance on the input graph. Defaults to True.\n",
    "    \"\"\"\n",
    "    pattern, collection_pattern, condition = lhs_to_graph(LHS, condition)\n",
    "    \n",
    "    matches = list(find_matches(input_graph, pattern, collection_pattern, condition))\n",
    "\n",
    "    # STAVS DEBUGGING\n",
    "    print(f\"Expected {len(expected)} matches:\")\n",
    "    for match in expected:\n",
    "        print(match)\n",
    "    print(f\"Found {len(matches)} matches:\")\n",
    "    for match in matches:\n",
    "        print(match.mapping)\n",
    "        \n",
    "    # Ensure that the number of matches and their mappings are as expected\n",
    "    assert all([match.mapping in expected for match in matches]) and len(matches) == len(expected)\n",
    "    \n",
    "    # STAV: This is the original code, but for debugging I want to see all the matches, so I commented it out\n",
    "    # Plot the first match if requested and there are any matches\n",
    "    # if plot and len(matches) > 0:\n",
    "    #     match = matches[0]\n",
    "    #     mapping = match.mapping\n",
    "         \n",
    "    #     print(f\"Plotting the match: {mapping}\")\n",
    "    #     draw_match(input_graph, match)\n",
    "\n",
    "    # Plot all matches\n",
    "    if plot and len(matches) > 0:\n",
    "        number_of_matches = len(matches)\n",
    "        print(f\"Plotting {number_of_matches} matches:\")\n",
    "        for match in matches:\n",
    "            mapping = match.mapping\n",
    "            print(f\"Plotting the match: {mapping}\")\n",
    "            draw_match(input_graph, match)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with simple cases, which do not take attributes into account at all. Consider the following quite-generic input graph (in which we will try to find matches for different patterns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBCiJdCkJbIkIKIl0KQ1siQwoiXQpEWyJECiJdCkEgLS0+IEIKQSAtLT4gQwpBIC0tPiBBCkMgLS0+IEMK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_graph = _create_graph(\n",
    "    ['A','B','C','D'], \n",
    "    [\n",
    "        ('A', 'B'),\n",
    "        ('A', 'C'),\n",
    "        ('A', 'A'),\n",
    "        ('C', 'C'),\n",
    "    ]\n",
    ")\n",
    "draw(input_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following tests, we try to match different patterns and make sure that the matcher found all of the possible matches. The first match in the list will be highlighted in the input graph (nodes and edges are colored in red), and printed above the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 2 matches:\n",
      "{'1': {'A'}}\n",
      "{'1': {'C'}}\n",
      "Found 2 matches:\n",
      "{'1': {'C'}}\n",
      "{'1': {'A'}}\n",
      "Plotting 2 matches:\n",
      "Plotting the match: {'1': {'C'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBCiJdCkJbIkIKIl0KQ1siQygxKQoiXQpzdHlsZSBDIHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7CkRbIkQKIl0KQSAtLT4gQgpBIC0tPiBDCkEgLS0+IEEKQyAtLT4gQwpsaW5rU3R5bGUgMyBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4Owo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': {'A'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBKDEpCiJdCnN0eWxlIEEgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQlsiQgoiXQpDWyJDCiJdCkRbIkQKIl0KQSAtLT4gQgpBIC0tPiBDCkEgLS0+IEEKbGlua1N0eWxlIDIgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQyAtLT4gQwo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Match all nodes 1 with self loops (both A and C)\n",
    "pattern, collection, condition = lhs_to_graph(\"1->1\")\n",
    "_assert_match(input_graph, \"1->1\", [{'1': {'A'}}, {'1': {'C'}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 6 matches:\n",
      "{'1': {'A'}, '2': {'B'}}\n",
      "{'1': {'A'}, '2': {'C'}}\n",
      "{'1': {'A'}, '2': {'D'}}\n",
      "{'1': {'C'}, '2': {'B'}}\n",
      "{'1': {'C'}, '2': {'A'}}\n",
      "{'1': {'C'}, '2': {'D'}}\n",
      "Found 6 matches:\n",
      "{'1': {'C'}, '2': {'B'}}\n",
      "{'1': {'C'}, '2': {'D'}}\n",
      "{'1': {'C'}, '2': {'A'}}\n",
      "{'1': {'A'}, '2': {'C'}}\n",
      "{'1': {'A'}, '2': {'B'}}\n",
      "{'1': {'A'}, '2': {'D'}}\n",
      "Plotting 6 matches:\n",
      "Plotting the match: {'1': {'C'}, '2': {'B'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBCiJdCkJbIkIoMikKIl0Kc3R5bGUgQiBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpDWyJDKDEpCiJdCnN0eWxlIEMgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKRFsiRAoiXQpBIC0tPiBCCkEgLS0+IEMKQSAtLT4gQQpDIC0tPiBDCmxpbmtTdHlsZSAzIHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': {'C'}, '2': {'D'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBCiJdCkJbIkIKIl0KQ1siQygxKQoiXQpzdHlsZSBDIHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7CkRbIkQoMikKIl0Kc3R5bGUgRCBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpBIC0tPiBCCkEgLS0+IEMKQSAtLT4gQQpDIC0tPiBDCmxpbmtTdHlsZSAzIHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': {'C'}, '2': {'A'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBKDIpCiJdCnN0eWxlIEEgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQlsiQgoiXQpDWyJDKDEpCiJdCnN0eWxlIEMgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKRFsiRAoiXQpBIC0tPiBCCkEgLS0+IEMKQSAtLT4gQQpDIC0tPiBDCmxpbmtTdHlsZSAzIHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': {'A'}, '2': {'C'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBKDEpCiJdCnN0eWxlIEEgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQlsiQgoiXQpDWyJDKDIpCiJdCnN0eWxlIEMgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKRFsiRAoiXQpBIC0tPiBCCkEgLS0+IEMKQSAtLT4gQQpsaW5rU3R5bGUgMiBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpDIC0tPiBDCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': {'A'}, '2': {'B'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBKDEpCiJdCnN0eWxlIEEgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQlsiQigyKQoiXQpzdHlsZSBCIHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7CkNbIkMKIl0KRFsiRAoiXQpBIC0tPiBCCkEgLS0+IEMKQSAtLT4gQQpsaW5rU3R5bGUgMiBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpDIC0tPiBDCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': {'A'}, '2': {'D'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBKDEpCiJdCnN0eWxlIEEgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQlsiQgoiXQpDWyJDCiJdCkRbIkQoMikKIl0Kc3R5bGUgRCBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpBIC0tPiBCCkEgLS0+IEMKQSAtLT4gQQpsaW5rU3R5bGUgMiBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpDIC0tPiBDCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all pairs of nodes 1, 2 where 1 has a self loop \n",
    "_assert_match(input_graph, '1->1, 2', [{'1': {'A'}, '2': {'B'}}, {'1': {'A'}, '2': {'C'}}, {'1': {'A'}, '2': {'D'}}\n",
    "                                        ,{'1': {'C'}, '2': {'B'}}, {'1': {'C'}, '2': {'A'}}, {'1': {'C'}, '2': {'D'}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 2 matches:\n",
      "{'1': {'A'}, '2': {'B'}}\n",
      "{'1': {'A'}, '2': {'C'}}\n",
      "Found 2 matches:\n",
      "{'1': {'A'}, '2': {'B'}}\n",
      "{'1': {'A'}, '2': {'C'}}\n",
      "Plotting 2 matches:\n",
      "Plotting the match: {'1': {'A'}, '2': {'B'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBKDEpCiJdCnN0eWxlIEEgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQlsiQigyKQoiXQpzdHlsZSBCIHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7CkNbIkMKIl0KRFsiRAoiXQpBIC0tPiBCCmxpbmtTdHlsZSAwIHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7CkEgLS0+IEMKQSAtLT4gQQpsaW5rU3R5bGUgMiBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpDIC0tPiBDCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': {'A'}, '2': {'C'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBKDEpCiJdCnN0eWxlIEEgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQlsiQgoiXQpDWyJDKDIpCiJdCnN0eWxlIEMgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKRFsiRAoiXQpBIC0tPiBCCkEgLS0+IEMKbGlua1N0eWxlIDEgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQSAtLT4gQQpsaW5rU3R5bGUgMiBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpDIC0tPiBDCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_assert_match(input_graph, '1->1, 1->2', [{'1': {'A'}, '2': {'B'}}, {'1': {'A'}, '2': {'C'}}]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 1 matches:\n",
      "{'1': {'C'}, '2': {'A'}}\n",
      "Found 1 matches:\n",
      "{'1': {'C'}, '2': {'A'}}\n",
      "Plotting 1 matches:\n",
      "Plotting the match: {'1': {'C'}, '2': {'A'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBKDIpCiJdCnN0eWxlIEEgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQlsiQgoiXQpDWyJDKDEpCiJdCnN0eWxlIEMgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKRFsiRAoiXQpBIC0tPiBCCkEgLS0+IEMKbGlua1N0eWxlIDEgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQSAtLT4gQQpDIC0tPiBDCmxpbmtTdHlsZSAzIHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_assert_match(input_graph, '1->1, 2->1', [{'1': {'C'}, '2': {'A'}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 0 matches:\n",
      "Found 0 matches:\n"
     ]
    }
   ],
   "source": [
    "# Find a circle in the graph + self loop. There is no such match in the graph\n",
    "_assert_match(input_graph, '1->1, 2->1->2', []) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 0 matches:\n",
      "Found 0 matches:\n"
     ]
    }
   ],
   "source": [
    "# Find five different nodes (the different pattern names enforce it).\n",
    "# There are only 4 nodes in the input graph, and so there are no matches.\n",
    "_assert_match(input_graph, '1,2,3,4,5', []) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to check more advanced features of both the parser and the matcher:\n",
    "* Checking for attributes (existance only)\n",
    "* Checking for attributes (match the values as well, using the parser-generated condition function)\n",
    "* Add user conditions\n",
    "* Anonymous nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a new input graph, which shows the connections between students and the courses they took throughout their degree:\n",
    "* Each node in the graph is associated with either a student or a course (and has an attribute \"type\" to denote which is which).\n",
    "* A student is defined by his/her name. Some students (not all of them) also metion their faculty.\n",
    "* A course is defined by its name. Some courses mention their associated number of units.\n",
    "* An edge from a student to a course denotes that the student took the course. It mentions the semester in which the student took the course.\n",
    "* An edge from a course to another course denotes that the first must be taken before the latter.\n",
    "\n",
    "The graph looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpBbGdvWyJBbGdvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KQUlbIkFJCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KTkxQWyJOTFAKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpEQlsiREIKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpCaW9bIkJpbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkpvaG4gLS0+fCJzZW09MyJ8IEJpbwpMdWN5IC0tPnwic2VtPTUifCBBbGdvCkx1Y3kgLS0+fCJzZW09NyJ8IEFJCkFteSAtLT58InNlbT01InwgQWxnbwpBbGdvIC0tPiBBSQpBSSAtLT4gTkxQCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_graph = _create_graph(\n",
    "    [\n",
    "        # Names\n",
    "        ('John', {'type': 'student', 'faculty': 'Biology'}),\n",
    "        ('Lucy', {'type': 'student', 'fauclty': 'CS'}),\n",
    "        ('Amy', {'type': 'student'}),\n",
    "        # Courses\n",
    "        ('Algo', {'type': 'course', 'units': 3}),\n",
    "        ('AI', {'type': 'course', 'units': 3}),\n",
    "        ('NLP', {'type': 'course', 'units': 5}),\n",
    "        ('DB', {'type': 'course'}),\n",
    "        ('Bio', {'type': 'course'})\n",
    "    ], \n",
    "    [\n",
    "        # Students take\n",
    "        ('John', 'Bio', {'sem': 3}),\n",
    "        ('Lucy', 'Algo', {'sem': 5}),\n",
    "        ('Lucy', 'AI', {'sem': 7}),\n",
    "        ('Amy', 'Algo', {'sem': 5}),\n",
    "        # KDAM\n",
    "        ('Algo', 'AI'),\n",
    "        ('AI', 'NLP'),\n",
    "    ]\n",
    ")\n",
    "draw(input_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now run some useful queries by matching patterns in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 3 matches:\n",
      "{'s': {'Amy'}}\n",
      "{'s': {'John'}}\n",
      "{'s': {'Lucy'}}\n",
      "Found 3 matches:\n",
      "{'s': {'John'}}\n",
      "{'s': {'Amy'}}\n",
      "{'s': {'Lucy'}}\n",
      "Plotting 3 matches:\n",
      "Plotting the match: {'s': {'John'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huKHMpCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0Kc3R5bGUgSm9obiBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpMdWN5WyJMdWN5CnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmF1Y2x0eT0jcXVvdDtDUyNxdW90OyJdCkFteVsiQW15CnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OyJdCkFsZ29bIkFsZ28KdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTMiXQpBSVsiQUkKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTMiXQpOTFBbIk5MUAp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9NSJdCkRCWyJEQgp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkJpb1siQmlvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KSm9obiAtLT58InNlbT0zInwgQmlvCkx1Y3kgLS0+fCJzZW09NSJ8IEFsZ28KTHVjeSAtLT58InNlbT03InwgQUkKQW15IC0tPnwic2VtPTUifCBBbGdvCkFsZ28gLS0+IEFJCkFJIC0tPiBOTFAK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': {'Amy'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteShzKQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpzdHlsZSBBbXkgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQWxnb1siQWxnbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCkFJWyJBSQp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCk5MUFsiTkxQCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz01Il0KREJbIkRCCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KQmlvWyJCaW8KdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpKb2huIC0tPnwic2VtPTMifCBCaW8KTHVjeSAtLT58InNlbT01InwgQWxnbwpMdWN5IC0tPnwic2VtPTcifCBBSQpBbXkgLS0+fCJzZW09NSJ8IEFsZ28KQWxnbyAtLT4gQUkKQUkgLS0+IE5MUAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': {'Lucy'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeShzKQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpzdHlsZSBMdWN5IHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7CkFteVsiQW15CnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OyJdCkFsZ29bIkFsZ28KdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTMiXQpBSVsiQUkKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTMiXQpOTFBbIk5MUAp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9NSJdCkRCWyJEQgp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkJpb1siQmlvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KSm9obiAtLT58InNlbT0zInwgQmlvCkx1Y3kgLS0+fCJzZW09NSJ8IEFsZ28KTHVjeSAtLT58InNlbT03InwgQUkKQW15IC0tPnwic2VtPTUifCBBbGdvCkFsZ28gLS0+IEFJCkFJIC0tPiBOTFAK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all students\n",
    "_assert_match(input_graph, 's[type=\"student\"]', [{'s': student} for student in [{'Amy'}, {'John'}, {'Lucy'}]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 5 matches:\n",
      "{'c': {'DB'}}\n",
      "{'c': {'NLP'}}\n",
      "{'c': {'AI'}}\n",
      "{'c': {'Algo'}}\n",
      "{'c': {'Bio'}}\n",
      "Found 5 matches:\n",
      "{'c': {'AI'}}\n",
      "{'c': {'NLP'}}\n",
      "{'c': {'Algo'}}\n",
      "{'c': {'DB'}}\n",
      "{'c': {'Bio'}}\n",
      "Plotting 5 matches:\n",
      "Plotting the match: {'c': {'AI'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpBbGdvWyJBbGdvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KQUlbIkFJKGMpCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0Kc3R5bGUgQUkgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKTkxQWyJOTFAKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpEQlsiREIKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpCaW9bIkJpbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkpvaG4gLS0+fCJzZW09MyJ8IEJpbwpMdWN5IC0tPnwic2VtPTUifCBBbGdvCkx1Y3kgLS0+fCJzZW09NyJ8IEFJCkFteSAtLT58InNlbT01InwgQWxnbwpBbGdvIC0tPiBBSQpBSSAtLT4gTkxQCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'c': {'NLP'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpBbGdvWyJBbGdvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KQUlbIkFJCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KTkxQWyJOTFAoYykKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpzdHlsZSBOTFAgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKREJbIkRCCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KQmlvWyJCaW8KdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpKb2huIC0tPnwic2VtPTMifCBCaW8KTHVjeSAtLT58InNlbT01InwgQWxnbwpMdWN5IC0tPnwic2VtPTcifCBBSQpBbXkgLS0+fCJzZW09NSJ8IEFsZ28KQWxnbyAtLT4gQUkKQUkgLS0+IE5MUAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'c': {'Algo'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpBbGdvWyJBbGdvKGMpCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0Kc3R5bGUgQWxnbyBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpBSVsiQUkKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTMiXQpOTFBbIk5MUAp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9NSJdCkRCWyJEQgp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkJpb1siQmlvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KSm9obiAtLT58InNlbT0zInwgQmlvCkx1Y3kgLS0+fCJzZW09NSJ8IEFsZ28KTHVjeSAtLT58InNlbT03InwgQUkKQW15IC0tPnwic2VtPTUifCBBbGdvCkFsZ28gLS0+IEFJCkFJIC0tPiBOTFAK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'c': {'DB'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpBbGdvWyJBbGdvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KQUlbIkFJCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KTkxQWyJOTFAKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpEQlsiREIoYykKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpzdHlsZSBEQiBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpCaW9bIkJpbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkpvaG4gLS0+fCJzZW09MyJ8IEJpbwpMdWN5IC0tPnwic2VtPTUifCBBbGdvCkx1Y3kgLS0+fCJzZW09NyJ8IEFJCkFteSAtLT58InNlbT01InwgQWxnbwpBbGdvIC0tPiBBSQpBSSAtLT4gTkxQCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'c': {'Bio'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpBbGdvWyJBbGdvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KQUlbIkFJCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KTkxQWyJOTFAKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpEQlsiREIKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpCaW9bIkJpbyhjKQp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCnN0eWxlIEJpbyBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpKb2huIC0tPnwic2VtPTMifCBCaW8KTHVjeSAtLT58InNlbT01InwgQWxnbwpMdWN5IC0tPnwic2VtPTcifCBBSQpBbXkgLS0+fCJzZW09NSJ8IEFsZ28KQWxnbyAtLT4gQUkKQUkgLS0+IE5MUAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all courses\n",
    "_assert_match(input_graph, 'c[type=\"course\"]', [{'c': course} for course in [{'DB'},{'NLP'},{'AI'},{'Algo'},{'Bio'}]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 3 matches:\n",
      "{'s': {'Amy'}}\n",
      "{'s': {'John'}}\n",
      "{'s': {'Lucy'}}\n",
      "Found 3 matches:\n",
      "{'s': {'Lucy'}}\n",
      "{'s': {'Amy'}}\n",
      "{'s': {'John'}}\n",
      "Plotting 3 matches:\n",
      "Plotting the match: {'s': {'Lucy'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeShzKQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpzdHlsZSBMdWN5IHN0cm9rZTpibHVlLHN0cm9rZS13aWR0aDo0cHg7CkFteVsiQW15CnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OyJdCkFsZ29bIkFsZ28KdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTMiXQpBSVsiQUkKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTMiXQpOTFBbIk5MUAp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9NSJdCkRCWyJEQgp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkJpb1siQmlvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KSm9obiAtLT58InNlbT0zInwgQmlvCkx1Y3kgLS0+fCJzZW09NSJ8IEFsZ28KTHVjeSAtLT58InNlbT03InwgQUkKQW15IC0tPnwic2VtPTUifCBBbGdvCkFsZ28gLS0+IEFJCkFJIC0tPiBOTFAK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': {'Amy'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteShzKQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpzdHlsZSBBbXkgc3Ryb2tlOmJsdWUsc3Ryb2tlLXdpZHRoOjRweDsKQWxnb1siQWxnbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCkFJWyJBSQp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCk5MUFsiTkxQCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz01Il0KREJbIkRCCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KQmlvWyJCaW8KdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpKb2huIC0tPnwic2VtPTMifCBCaW8KTHVjeSAtLT58InNlbT01InwgQWxnbwpMdWN5IC0tPnwic2VtPTcifCBBSQpBbXkgLS0+fCJzZW09NSJ8IEFsZ28KQWxnbyAtLT4gQUkKQUkgLS0+IE5MUAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': {'John'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huKHMpCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0Kc3R5bGUgSm9obiBzdHJva2U6Ymx1ZSxzdHJva2Utd2lkdGg6NHB4OwpMdWN5WyJMdWN5CnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmF1Y2x0eT0jcXVvdDtDUyNxdW90OyJdCkFteVsiQW15CnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OyJdCkFsZ29bIkFsZ28KdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTMiXQpBSVsiQUkKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTMiXQpOTFBbIk5MUAp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9NSJdCkRCWyJEQgp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkJpb1siQmlvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KSm9obiAtLT58InNlbT0zInwgQmlvCkx1Y3kgLS0+fCJzZW09NSJ8IEFsZ28KTHVjeSAtLT58InNlbT03InwgQUkKQW15IC0tPnwic2VtPTUifCBBbGdvCkFsZ28gLS0+IEFJCkFJIC0tPiBOTFAK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all students that took some course (all of them)\n",
    "#TODO: I need to go back and understand how to handle anonymous nodes like Dean asked - it messes up when filtering by attributes\n",
    "_assert_match(input_graph, 's[type=\"student\"]->_[type=\"course\"]', [{'s': {'Amy'}}, {'s': {'John'}}, {'s': {'Lucy'}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all students that took some 3-units course\n",
    "_assert_match(input_graph, 's[type=\"student\"]->_[type=\"course\", units=3]', [{'s': 'Amy'}, {'s': 'Lucy'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all students that took some 3-units course, and the associated courses\n",
    "_assert_match(input_graph, 's[type=\"student\"]->c[type=\"course\", units=3]', [\n",
    "    {'s': 'Amy', 'c': 'Algo'}, {'s': 'Lucy', 'c': 'Algo'}, {'s': 'Lucy', 'c': 'AI'}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all students which took two courses (and the courses) \n",
    "_assert_match(input_graph, 's[type=\"student\"]->c1[type=\"course\"], s->c2[type=\"course\"]', [ \n",
    "    {'s': 'Lucy', 'c1': 'AI', 'c2': 'Algo'},\n",
    "    {'s': 'Lucy', 'c1': 'Algo', 'c2': 'AI'}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all tripltes c1, c2, c3 of courses such that c1 is a prerequisite of c2, and the same for c2 and c3\n",
    "_assert_match(input_graph, 'c1[type=\"course\"]->c2[type=\"course\"]->c3[type=\"course\"]', [\n",
    "    {'c1': 'Algo', 'c2': 'AI', 'c3': 'NLP'}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all students that took a course in their 7th semester\n",
    "_assert_match(input_graph, 's[type=\"student\"]-[sem=7]->_[type=\"course\"]', [ \n",
    "    {'s': 'Lucy'}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all students that took a course before their 5th semester (use user-defined condition)\n",
    "_assert_match(input_graph, 's[type=\"student\"]-[sem]->c[type=\"course\"]', [\n",
    "    {'s': 'John', 'c': 'Bio'}\n",
    "], condition=lambda match: match['s->c']['sem'] < 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POC For Large Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POC: High number of nodes, solved with attribute filtering\n",
    "num_nodes = 100000\n",
    "\n",
    "input_graph = _create_graph(\n",
    "    [n for n in range(num_nodes)] + [(num_nodes+1, {'attr': 15}), (num_nodes+2, {'attr': 15})], \n",
    "    [\n",
    "        (num_nodes+1, num_nodes+2),\n",
    "        (2,4),\n",
    "        (3,1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "_assert_match(input_graph, 'X[attr]->Y[attr]', [{'X': num_nodes+1, 'Y': num_nodes+2}], plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collections Feature - Matcher Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgoxWyIxCnZhbD0xIl0KMlsiMgp2YWw9MiJdCjNbIjMKdmFsPTMiXQo0WyI0CnZhbD00Il0KNVsiNQp2YWw9NSJdCjEgLS0+IDIKMSAtLT4gMwozIC0tPiA0CjMgLS0+IDUK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = _create_graph(\n",
    "    [('1', {'val': 1}), ('2', {'val': 2}), ('3', {'val': 3}), ('4',{'val': 4}), ('5',{'val': 5})],\n",
    "    [('1','2'), ('1','3'), ('3','4'), ('3','5')]\n",
    ")\n",
    "draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1295], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m match\u001b[38;5;241m.\u001b[39mcollection_mapping \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m}}\n\u001b[1;32m     13\u001b[0m     last_x\u001b[38;5;241m.\u001b[39mappend(match[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(matches) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Ensuring that in a case where we match all modes, and collect all nodes (with no specific connection to the match), \n",
    "there's actually will be a collection of all nodes for each match \n",
    "\"\"\"\n",
    "\n",
    "input_graph = g.copy()\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x;y')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "last_x = []\n",
    "for match in matches:    \n",
    "    assert match['x'] not in last_x\n",
    "    assert match.collection_mapping == {'y': {'4', '5', '1', '3', '2'}}\n",
    "    last_x.append(match['x'])\n",
    "assert len(matches) == 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Ensuring that:\n",
    "1.⁠ ⁠We get four matches based on the pattern\n",
    "2.⁠ ⁠We ensure the collection for each is correct\n",
    "\"\"\"\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x->y;x->z')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "for match in matches:\n",
    "    assert match.mapping in [{'x': '1', 'y': '3'}, {'x': '1', 'y': '2'}, {'x': '3', 'y': '5'}, {'x': '3', 'y': '4'}]\n",
    "    if (match['x']['val'] == 1):\n",
    "        assert match.collection_mapping == {'z': {'3', '2'}}\n",
    "    else:\n",
    "        assert match['x']['val'] == 3\n",
    "        assert match.collection_mapping == {'z': {'5', '4'}}\n",
    "assert len(matches) == 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "Ensuring that:\n",
    "1.⁠ ⁠We get four matches based on the pattern\n",
    "2.⁠ ⁠For each match, there is an empty collection for (x,z), z, (z,y)\n",
    "#TODO: No matches at all! no empty collections\n",
    "\"\"\"\n",
    "\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x->y;x->z->y')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "#for match in matches:\n",
    "#        assert match.mapping in [{'x': '1', 'y': '3'}, {'x': '1', 'y': '2'}, {'x': '3', 'y': '5'}, {'x': '3', 'y': '4'}]\n",
    "#        assert match.collection_mapping == {}\n",
    "assert len(matches) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Ensuring that:\n",
    "1.⁠ ⁠We get two matches based on the pattern\n",
    "2.⁠ ⁠For each match, the collections are created correctly - they all should be empty\n",
    "#TODO: No matches at all! no empty collections\n",
    "\"\"\"\n",
    "\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x->y->z;x->a->b->c')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "#for match in matches:\n",
    "#        assert match.mapping in [{'x': '1', 'y': '3', 'z': '5'}, {'x': '1', 'y': '3', 'z': '4'}]\n",
    "#        assert match.collection_mapping == {}\n",
    "assert len(matches) == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Ensuring that:\n",
    "1.⁠ ⁠We get two matches based on the pattern\n",
    "2.⁠ ⁠For each match, the collections are created correctly - they all should be empty\n",
    "#TODO: No matches at all! no empty collections\n",
    "\"\"\"\n",
    "\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x->y->z;x->a,a->b,b->c')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "#for match in matches:\n",
    "#        assert match.mapping in [{'x': '1', 'y': '3', 'z': '5'}, {'x': '1', 'y': '3', 'z': '4'}]\n",
    "#        assert match.collection_mapping == {}\n",
    "assert len(matches) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Ensuring that:\n",
    "1.⁠ ⁠We get two matches based on the pattern\n",
    "2.⁠ ⁠For each match, the collections are created correctly - they all should be empty\n",
    "#TODO: No matches at all! no empty collections\n",
    "\"\"\"\n",
    "\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x->y->z;x->a,a->b,z->c')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "#for match in matches:\n",
    "#        assert match.mapping in [{'x': '1', 'y': '3', 'z': '5'}, {'x': '1', 'y': '3', 'z': '4'}]\n",
    "#        assert match.collection_mapping == {}\n",
    "assert len(matches) == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = _create_graph(\n",
    "    [('1', {'val': 1}), ('2', {'val': 2}), ('3', {'val': 3}), ('4',{'val': 4}), ('5',{'val': 5})],\n",
    "    [('1','2'), ('1','3'), ('3','4'), ('3','5')]\n",
    ")\n",
    "draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern, collections_pattern, condition = lhs_to_graph('x[val];x[val]->y[val]->z[val]')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "assert len(matches) == 1\n",
    "assert matches[0]['x']['val'] == 1\n",
    "assert matches[0].collection_mapping == {'y': {'3'}, 'z': {'4', '5'}}\n",
    "print(match.mapping, match.collection_mapping)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
