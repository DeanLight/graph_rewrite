{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Go over all comments and make sure they are correct and up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from itertools import product, permutations\n",
    "from typing import Tuple, Iterator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "In the previous modules, the LHS Parser received an LHS string, describing some graph pattern, and parsed it to an equivalent NetworkX DiGraph. In the following module, we search for **matches** to this pattern in our input graph - That is, find all subgraphs of our input graph, which have the same structure as the pattern in terms of nodes, the edges connecting them and the attributes they all have. \n",
    "\n",
    "Each match is basically a mapping from a subset of the input graph nodes to a the pattern nodes (as we can deduce what are the matched edges and attributes accordingly).\n",
    "\n",
    "The **Matcher** in this module does the following:\n",
    "* **Searches for matches** in the input graph, according to some LHS pattern graph.\n",
    "* **Filters matches** based on an explicit boolean function, and / or constraints given to the matcher by the parser to be handled later.\n",
    "* **Constructs a list of Match objects**, each corresponds to one of the filtered matches we've found. The list will be used in later modules, and will also allow users to view the matches and to use them imperatively.\n",
    "\n",
    "The final, filtered list of Match objects is returned from this module's main function, **find_matches**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import *\n",
    "from networkx import DiGraph\n",
    "from networkx.algorithms import isomorphism # check subgraph's isom.\n",
    "import itertools # iterating over all nodes\\edges combinations\n",
    "\n",
    "from graph_rewrite.core import NodeName, _create_graph, draw\n",
    "from graph_rewrite.lhs import lhs_to_graph\n",
    "from graph_rewrite.match_class import Match, mapping_to_match, is_anonymous_node,draw_match"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Matches\n",
    "Given an input graph and a pattern graph, we want to find the list of matches from pattern nodes to input-graph nodes, each constructs a corresponding Match object. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Attribute Existence and Constant Values\n",
    "A crucial aspect of finding matches is comparing the attributes of nodes to determine whether they are compatible. Nodes that match based on either the existence of specific attributes or constant attribute values are considered candidates. These candidates are then further refined to identify all valid matches for the given pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# TODO: Ensure we separate between constant attributes and existence checks (constants).\n",
    "# a[id] -> existence check (can be checked before combinatorics)\n",
    "# a[id=Constant(3)] -> constant value check (can be checked before combinatorics)\n",
    "\n",
    "# TODO: Email Dean regarding the parser ability to support constant values in the pattern graph - it is currently not supported, and so all constant values will still\n",
    "#  result in a None value in the pattern graph.\n",
    "class Constant:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "\n",
    "def _attributes_match(pattern_attrs: dict, input_attrs: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the input attributes match the pattern attributes.\n",
    "\n",
    "    This function supports both:\n",
    "    - Existence checks (ensures that required attributes exist).\n",
    "    - Constant value checks (ensures that constant values match).\n",
    "\n",
    "    Args:\n",
    "        pattern_attrs (dict): Attributes of the pattern (node or edge).\n",
    "        input_attrs (dict): Attributes of the input (node or edge).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the input attributes match the pattern attributes, False otherwise.\n",
    "    \"\"\"\n",
    "    for attr_name, attr_value in pattern_attrs.items():\n",
    "        if attr_name not in input_attrs:  # If the attribute does not exist, return False\n",
    "            return False\n",
    "        \n",
    "        if attr_value is None: # If the attribute exists, but the value is None, continue to the next attribute\n",
    "            continue\n",
    "\n",
    "        # TODO: This is not supported yet due to the parser not supporting constant values in the pattern graph - we will never reach this point, and it is implemented for future use, \n",
    "        # once the parser supports it.\n",
    "        if isinstance(attr_value, Constant):  # If the attribute exists, and the value is a constant, check if the value matches\n",
    "            if input_attrs[attr_name] != attr_value.value:\n",
    "                return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Narrow Down Search Space\n",
    "Using the functions presented thus far, the search for matches might take a lot of time if the graph has a high number of nodes / edges. Nodes which are no real candidate to match any pattern node (do not share attributes with any pattern node) are checked eitherway, which is extermely inefficient. \n",
    "\n",
    "Therefore, before we search for matches in our input graph, we will reduce it to only contain the nodes that might match any of the pattern nodes (and their connected edges as well). This might improve the whole matching performance. The following function is used in order to do exactly that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _find_input_nodes_candidates(pattern_node: NodeName, pattern: DiGraph, input_graph: DiGraph) -> set[NodeName]:\n",
    "    \"\"\"\n",
    "    Given a pattern node and an input graph, return a set of input graph nodes that:\n",
    "    - Contain the required attributes of the pattern node, including constant value checks (if specified) and existence checks (if no value is specified / no constant value).\n",
    "    - Have at least one edge with matching attributes for each edge of the pattern node that has attributes specified.\n",
    "\n",
    "    Args:\n",
    "        pattern_node (NodeName): The pattern node.\n",
    "        pattern (DiGraph): The pattern graph.\n",
    "        input_graph (DiGraph): The input graph.\n",
    "\n",
    "    Returns:\n",
    "        set[NodeName]: A set of input graph nodes that match the required attributes and have at least one matching edge.\n",
    "    \"\"\"\n",
    "\n",
    "    pattern_node_attrs = pattern.nodes[pattern_node]\n",
    "\n",
    "    if \"_id\" in pattern_node_attrs: #TODO: understand why this is here (_id)\n",
    "        input_node_id = pattern_node_attrs.pop(\"_id\")\n",
    "        input_nodes_to_check = [input_node_id]\n",
    "    else:\n",
    "        input_nodes_to_check = list(input_graph.nodes)\n",
    "\n",
    "    # Filter nodes by attributes first\n",
    "    candidate_nodes = {\n",
    "        input_node\n",
    "        for input_node in input_nodes_to_check\n",
    "        if _attributes_match(pattern_node_attrs, input_graph.nodes[input_node])\n",
    "    }\n",
    "\n",
    "    return candidate_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _filter_edge_candidates(input_graph: DiGraph, pattern: DiGraph, src_pattern_node: NodeName, dst_pattern_node: NodeName, \n",
    "                               src_candidates: Set[NodeName], dst_candidates: Set[NodeName]) -> Set[Tuple[NodeName, NodeName]]:\n",
    "    \"\"\"\n",
    "    Filter the input node candidates for two pattern nodes by checking if the edges between them in the input graph exist\n",
    "    and match the pattern edge attributes.\n",
    "\n",
    "    This function reduces the number of candidate pairs before generating assignments in _find_pattern_based_matches.\n",
    "\n",
    "    Args:\n",
    "        input_graph (DiGraph): The input graph.\n",
    "        pattern (DiGraph): The pattern graph (provides the edge attributes).\n",
    "        src_pattern_node (NodeName): The source pattern node.\n",
    "        dst_pattern_node (NodeName): The destination pattern node.\n",
    "        src_candidates (Set[NodeName]): Current candidates for the source pattern node.\n",
    "        dst_candidates (Set[NodeName]): Current candidates for the destination pattern node.\n",
    "\n",
    "    Returns:\n",
    "        Set[Tuple[NodeName, NodeName]]: A set of valid candidate edge assignments (source, destination).\n",
    "    \"\"\"\n",
    "    pattern_edge_attrs = pattern.get_edge_data(src_pattern_node, dst_pattern_node, default={})\n",
    "\n",
    "    # Filter input edge candidates for the pattern edge by checking if the input edge exists and matches the pattern edge attributes (if specified)\n",
    "    valid_edge_candidates = {\n",
    "        (src_candidate, dst_candidate)\n",
    "        for src_candidate, dst_candidate in product(src_candidates, dst_candidates)\n",
    "        if (src_candidate, dst_candidate) in input_graph.edges and\n",
    "           _attributes_match(pattern_edge_attrs, input_graph.get_edge_data(src_candidate, dst_candidate, default={}))\n",
    "    }\n",
    "\n",
    "    return valid_edge_candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Pattern Based Matches\n",
    "NetworkX provides an out-of-the-box isomorphism matcher, which compares the structure of two graphs and tells whether they are isomorphic (have the same nodes and edges). We utilize this isomorphism matcher by beginning our matching process with structural matches, after filtering out candidates that do not match based on existance of attributes or constant values of attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _add_candidates_to_assignment(src_candidate: NodeName, dst_candidate: NodeName, partial_assignment: Dict[NodeName, NodeName], \n",
    "                                  src_pattern_node: NodeName, dst_pattern_node: NodeName) -> Optional[frozenset]:\n",
    "    \"\"\"\n",
    "    Helper function to handle the case of adding src and dst candidates to the partial assignment\n",
    "    based on different conditions (both unassigned, one already assigned correctly, etc.).\n",
    "\n",
    "    Args:\n",
    "        src_candidate: The candidate for the source pattern node.\n",
    "        dst_candidate: The candidate for the destination pattern node.\n",
    "        partial_assignment: The current partial assignment being considered.\n",
    "        src_pattern_node: The source pattern node.\n",
    "        dst_pattern_node: The destination pattern node.\n",
    "\n",
    "    Returns:\n",
    "        A frozen set of the new assignment if valid, or None if it doesn't apply.\n",
    "    \"\"\"\n",
    "    new_assignment = partial_assignment.copy()\n",
    "    src_assigned = src_candidate in partial_assignment.values()\n",
    "    dst_assigned = dst_candidate in partial_assignment.values()\n",
    "\n",
    "    # Case 1: Neither src nor dst are assigned, add both\n",
    "    if not src_assigned and not dst_assigned:\n",
    "        new_assignment[src_pattern_node] = src_candidate\n",
    "        new_assignment[dst_pattern_node] = dst_candidate\n",
    "        return frozenset(new_assignment.items())\n",
    "\n",
    "    # Case 2: src is already correctly assigned, add dst\n",
    "    elif src_assigned and partial_assignment[src_pattern_node] == src_candidate and not dst_assigned:\n",
    "        new_assignment[dst_pattern_node] = dst_candidate\n",
    "        return frozenset(new_assignment.items())\n",
    "\n",
    "    # Case 3: dst is already correctly assigned, add src\n",
    "    elif dst_assigned and partial_assignment[dst_pattern_node] == dst_candidate and not src_assigned:\n",
    "        new_assignment[src_pattern_node] = src_candidate\n",
    "        return frozenset(new_assignment.items())\n",
    "\n",
    "    return None  # No valid assignment if none of the cases match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _find_pattern_based_matches(graph: DiGraph, pattern: DiGraph) -> Iterator[Tuple[DiGraph, Dict[NodeName, NodeName]]]:\n",
    "    \"\"\"\n",
    "    Find all subgraphs in the input graph that match the given pattern graph based on both structure (nodes and edges)\n",
    "    and attributes (existence of attributes or constant value checks).\n",
    "\n",
    "    A subgraph is considered isomorphic if it has the same structure (nodes and edges) as the pattern graph\n",
    "    and the attributes of the nodes and edges match the specified attributes in the pattern graph.\n",
    "\n",
    "    Args:\n",
    "        graph (DiGraph): The graph to search for matches.\n",
    "        pattern (DiGraph): The pattern graph representing the structure and attributes to match.\n",
    "\n",
    "    Yields:\n",
    "        Iterator[Tuple[DiGraph, Dict[NodeName, NodeName]]]: Tuples of (subgraph, mapping),\n",
    "        where subgraph is the matched subgraph, and mapping is a dictionary mapping nodes in the\n",
    "        subgraph to nodes in the pattern.\n",
    "    \"\"\"\n",
    "\n",
    "    #  Identify lonely pattern nodes (nodes with no edges) and their candidates in the input graph\n",
    "    lonely_pattern_nodes = [n for n in pattern.nodes if pattern.in_degree(n) == 0 and pattern.out_degree(n) == 0]\n",
    "    lonely_pattern_nodes_to_input_candidates = {n: _find_input_nodes_candidates(n, pattern, graph) for n in lonely_pattern_nodes}\n",
    "\n",
    "    # For pattern edges, gather valid edge candidates (pairs of nodes with matching attributes)\n",
    "    edge_candidates = {}\n",
    "    for src_pattern_node, dst_pattern_node in pattern.edges:\n",
    "        src_candidates = _find_input_nodes_candidates(src_pattern_node, pattern, graph)\n",
    "        dst_candidates = _find_input_nodes_candidates(dst_pattern_node, pattern, graph)\n",
    "        edge_candidates[(src_pattern_node, dst_pattern_node)] = _filter_edge_candidates(\n",
    "            graph, pattern, src_pattern_node, dst_pattern_node, src_candidates, dst_candidates)\n",
    "\n",
    "    # Initialize partial assignments based on valid edge candidates\n",
    "    partial_assignments = set()\n",
    "\n",
    "    for (src_pattern_node, dst_pattern_node), valid_edge_candidates in edge_candidates.items():\n",
    "        new_assignments = set()\n",
    "\n",
    "        for src_candidate, dst_candidate in valid_edge_candidates:\n",
    "            for partial_assignment in partial_assignments or [{}]:\n",
    "                new_assignment = _add_candidates_to_assignment(src_candidate, dst_candidate, partial_assignment, src_pattern_node, dst_pattern_node)\n",
    "                if new_assignment:\n",
    "                    new_assignments.add(new_assignment)\n",
    "\n",
    "        if not new_assignments:  # If no new assignments are found for a pair of pattern nodes, the pattern cannot be matched\n",
    "            return\n",
    "        partial_assignments = new_assignments\n",
    "\n",
    "    # Add lonely node candidates (nodes without edges) to the assignments\n",
    "    for pattern_node in lonely_pattern_nodes:\n",
    "        lonely_node_candidates = lonely_pattern_nodes_to_input_candidates[pattern_node]\n",
    "        new_assignments = set()\n",
    "\n",
    "        for candidate in lonely_node_candidates:\n",
    "            for partial_assignment in partial_assignments or [{}]:\n",
    "                if candidate not in dict(partial_assignment).values():\n",
    "                    new_assignment = dict(partial_assignment).copy()\n",
    "                    new_assignment[pattern_node] = candidate\n",
    "                    new_assignments.add(frozenset(new_assignment.items()))  # Ensuring the assignment remains immutable and unique\n",
    "\n",
    "        partial_assignments = new_assignments\n",
    "\n",
    "    # Filter and yield valid subgraphs that match the pattern (structurally and by attributes)\n",
    "    for assignment in partial_assignments:\n",
    "        assignment_dict = dict(assignment)  # Convert frozen set back to a dict\n",
    "        subgraph = graph.subgraph(assignment_dict.values())\n",
    "\n",
    "        # Validate the subgraph for isomorphism against the pattern\n",
    "        if isomorphism.is_isomorphic(subgraph, pattern, node_match=_attributes_match, edge_match=_attributes_match):\n",
    "            yield subgraph, assignment_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#OLD    \n",
    "'''\n",
    "    # We find all possible candidates for each node in the pattern, by checking the attributes of the nodes in the graph\n",
    "    pattern_to_input_candidates = {pattern_node: _find_input_nodes_with_pattern_attributes(pattern.nodes[pattern_node], graph) for pattern_node in pattern.nodes}\n",
    "    candidate_assignments = itertools.product(*(pattern_to_input_candidates[pattern_node] for pattern_node in list(pattern.nodes)))\n",
    "    for assignment in candidate_assignments:\n",
    "        # Make sure the sub_nodes are unique - we don't want to have multiple nodes in the subgraph that are mapped to the same node in the pattern\n",
    "        if len(set(assignment)) != len(assignment): \n",
    "            continue\n",
    "        assignment_mapping = dict(zip(list(pattern.nodes), assignment))\n",
    "        subg = DiGraph()\n",
    "        subg.add_nodes_from(list(assignment))\n",
    "        for pattern_edge in list(pattern.edges):\n",
    "            graph_edge = (assignment_mapping[pattern_edge[0]], assignment_mapping[pattern_edge[1]])\n",
    "            if graph_edge in graph.edges and _input_node_has_pattern_node_attributes(graph.edges[graph_edge], pattern.edges[edge]):\n",
    "              subg.add_edge(graph_edge[0], graph_edge[1])\n",
    "            else: # In that case we don't need to check the rest of the isomorphism\n",
    "                break\n",
    "                             \n",
    "        # We only yield mappings for subgraphs that have the same amount of edges as the pattern - otherwise the subgraph won't be an isomorphism\n",
    "        if len(subg.edges) == len(pattern.edges):\n",
    "            yield assignment_mapping\n",
    "'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering Matches\n",
    "The only thing we ignored up until now is attribute values. As metioned above, the LHS Parser does not include required attribute values in the pattern graph. Instead, it constructs a boolean function which receives a Match object and checks whether the match it represents has the required attribute values (if there are any). \n",
    "\n",
    "This boolean function is further extended by the user of the library, which can pass as parameter a function of the same format, which filteres a list of Match objects based on any condition it wishes to apply. The LHS Parser, in addition to the pattern graph, provides the extended filtering function, that mixes both the user and the parser constraints which were not handled by the matcher so far.\n",
    "\n",
    "Later in this module, we will use the extended function to filter the list of Match objects we get from the structural and attribute-existence-based matchers. The signature of that function will be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "FilterFunc = Callable[[Match], bool]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting It All Togehter\n",
    "Given our ability to find matches (both structural and in terms of attribute existence) between two graphs, as well as filtering matches according to desired conditions and constraints, we can finally find complete matches of the pattern in our input graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define one last auxiliary function, which removes duplicated matches based on their mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _filter_duplicated_matches(matches: list[Match]) -> Iterator[Match]:\n",
    "    \"\"\"Remove duplicates from a list of Matches, based on their mappings. Return an iterator of the matches without duplications.\n",
    "\n",
    "    Args:\n",
    "        matches (list[Match]): list of Match objects\n",
    "\n",
    "    Yields:\n",
    "        Iterator[list[Match]]: Iterator of the matches without duplications.\n",
    "    \"\"\"\n",
    "\n",
    "    # We avoid using set here to avoid instantiation of all matches - so this is the most efficient way to do it\n",
    "    seen = set()\n",
    "    for match in matches:\n",
    "        if match not in seen:  # O(1) average time complexity for set lookup\n",
    "            seen.add(match)  # O(1) average time complexity for adding to set\n",
    "            yield match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _find_intersecting_pattern_nodes(exact_match_pattern: DiGraph, collection_pattern: DiGraph) -> set:\n",
    "    \"\"\"\n",
    "    Find the intersecting pattern nodes between the exact match pattern and the collection pattern.\n",
    "\n",
    "    The intersecting pattern nodes are those that appear in both the exact match pattern \n",
    "    (i.e., pattern nodes that aim to match a single, unique input node) and the collection pattern \n",
    "    (i.e., pattern nodes that aim to match multiple input nodes).\n",
    "\n",
    "    Args:\n",
    "        exact_match_pattern (DiGraph): The pattern graph representing nodes that match exactly one input node.\n",
    "        collection_pattern (DiGraph): The pattern graph representing nodes that match multiple input nodes.\n",
    "\n",
    "    Returns:\n",
    "        set: A set of pattern nodes that are present in both the exact match pattern and the collection pattern.\n",
    "    \"\"\"\n",
    "    intersecting_pattern_nodes = set(exact_match_pattern.nodes) & set(collection_pattern.nodes)\n",
    "    return intersecting_pattern_nodes\n",
    "\n",
    "\n",
    "#| export\n",
    "def _add_collections_to_exact_matches(input_graph: DiGraph, collection_pattern: DiGraph, \n",
    "                                      exact_matches: Set[Dict[NodeName, NodeName]], intersecting_pattern_nodes: Set[NodeName]\n",
    "                                      ) -> Iterator[Dict[NodeName, Set[NodeName]]]:\n",
    "    \"\"\"\n",
    "    Add collection matches to the existing exact matches by finding subgraph matches for collection pattern nodes\n",
    "    and merging them with the given exact match mapping.\n",
    "\n",
    "    This function finds matches in the input graph that satisfy both the exact match pattern (pattern nodes \n",
    "    that aim to match exactly one input node) and the collection pattern (pattern nodes that aim to match \n",
    "    multiple input nodes).\n",
    "\n",
    "    Args:\n",
    "        input_graph (DiGraph): The input graph where collection matches are searched.\n",
    "        collection_pattern (DiGraph): The pattern graph representing nodes that match multiple input nodes.\n",
    "        exact_matches (Set[Dict[NodeName, NodeName]]): The set of exact matches, where each pattern node \n",
    "            is mapped to a single input node.\n",
    "        intersecting_pattern_nodes (Set[NodeName]): The set of pattern nodes that intersect between the \n",
    "            exact match pattern and collection pattern.\n",
    "\n",
    "    Yields:\n",
    "        Iterator[Dict[NodeName, Set[NodeName]]]: An iterator over the updated mappings, where each includes both \n",
    "        the previous exact match mapping and the newly found collection matches for this exact match.\n",
    "    \"\"\"\n",
    "    input_graph_copy = input_graph.copy()\n",
    "\n",
    "    # Enrich the exact match mapping with the corresponding collection matches.\n",
    "    # This involves moving to set semantics for exact matches nodes and adding collection matches.\n",
    "    for exact_match in exact_matches:\n",
    "        updated_mapping = {pattern_node: {input_node} for pattern_node, input_node in exact_match.items()}\n",
    "        non_intersecting_collection_pattern_nodes = set(collection_pattern.nodes) - intersecting_pattern_nodes\n",
    "        updated_mapping.update({pattern_node: set() for pattern_node in non_intersecting_collection_pattern_nodes})\n",
    "\n",
    "        # Lock intersecting pattern nodes to their corresponding input node in the exact match\n",
    "        collection_pattern_copy = collection_pattern.copy()\n",
    "        for intersecting_pattern_node in intersecting_pattern_nodes:\n",
    "            collection_pattern_copy.nodes[intersecting_pattern_node]['_id'] = exact_match[intersecting_pattern_node]\n",
    "\n",
    "        # Find collection matches using the locked pattern\n",
    "        collection_matches = list(_find_pattern_based_matches(input_graph_copy, collection_pattern_copy))\n",
    "\n",
    "        # Add matches for collection pattern nodes\n",
    "        for collection_match in collection_matches:\n",
    "            for collection_pattern_node, matched_input_nodes in collection_match.items():\n",
    "                if collection_pattern_node not in intersecting_pattern_nodes: # We already have the exact match for these nodes\n",
    "                    updated_mapping[collection_pattern_node].add(matched_input_nodes)  # Add the matched input node\n",
    "\n",
    "        yield updated_mapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now combining everything we saw in order to find the matches of a pattern in our input graph. The matches are returned as a (filtered) list of Match objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_matches(input_graph: DiGraph, exact_match_pattern: DiGraph, collections_pattern: DiGraph = None, \n",
    "                 condition: FilterFunc = lambda match: True) -> Iterator[Match]:\n",
    "    \"\"\"\n",
    "    Find all matches of a pattern graph in an input graph, satisfying a certain condition.\n",
    "\n",
    "    This function identifies subgraphs of the input graph that match the exact match pattern \n",
    "    and the collections pattern (if provided) based on structure, attributes, and additional conditions \n",
    "    specified by the user.\n",
    "\n",
    "    Args:\n",
    "        input_graph (DiGraph): A graph where matches are searched.\n",
    "        exact_match_pattern (DiGraph): The pattern graph representing exact matches (nodes mapped to one input node).\n",
    "        collections_pattern (DiGraph, optional): A pattern graph representing nodes that can map to multiple input nodes. Defaults to None.\n",
    "        condition (FilterFunc, optional): A function that receives a Match object and checks if a condition holds. \n",
    "                                          Defaults to a function that always returns True.\n",
    "\n",
    "    Yields:\n",
    "        Iterator[Match]: Iterator of Match objects, each representing a match of the pattern in the input graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # Find all exact matches (isomorphisms) based on structure and attributes.\n",
    "    exact_matches = {frozenset(mapping.items()) for _, mapping in _find_pattern_based_matches(input_graph, exact_match_pattern)}\n",
    "\n",
    "    # If a collections pattern is provided, enrich exact matches by adding matching collections.\n",
    "    if collections_pattern:\n",
    "        intersecting_pattern_nodes = _find_intersecting_pattern_nodes(exact_match_pattern, collections_pattern)\n",
    "        updated_matches_with_collections = _add_collections_to_exact_matches(input_graph, collections_pattern, exact_matches, intersecting_pattern_nodes)\n",
    "    else:\n",
    "        #TODO: verify this\n",
    "        # If no collections, we proceed with exact matches only, we just move it to the correct format of the updated_matches_with_collections\n",
    "        updated_matches_with_collections = [{pattern_node: {input_node} for pattern_node, input_node in exact_match.items()} \n",
    "                                            for exact_match in exact_matches]\n",
    "\n",
    "    exact_pattern_nodes = set(exact_match_pattern.nodes)\n",
    "\n",
    "    # TODO: verify this\n",
    "    pattern_nodes = set(exact_pattern_nodes) | set(collections_pattern.nodes)\n",
    "    pattern_edges = set(collections_pattern.edges) | set(exact_match_pattern.edges)\n",
    "\n",
    "    # Generate matches with and without filtering out anonymous nodes.\n",
    "    # TODO: ask Dean about the anonymous nodes\n",
    "    matches_with_filtered_versions = [(mapping_to_match(input_graph, pattern_nodes, pattern_edges, mapping, exact_pattern_nodes, filter=False),\n",
    "                                       mapping_to_match(input_graph, pattern_nodes, pattern_edges, mapping, exact_pattern_nodes))\n",
    "                                       for mapping in updated_matches_with_collections]\n",
    "    \n",
    "    # Filter matches using the provided condition function, based on the unfiltered match.\n",
    "    filtered_matches = [filtered_match for (unfiltered_match, filtered_match) in matches_with_filtered_versions \n",
    "                        if condition(unfiltered_match)]\n",
    "\n",
    "    # Remove any duplicate matches (duplicates might be introduced due to filtering out anonymous nodes).\n",
    "    yield from _filter_duplicated_matches(filtered_matches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assert_match(input_graph: DiGraph, LHS: str, expected: list[dict], condition=lambda x: True, plot=True):\n",
    "    \"\"\"Match the pattern in the input graph, and validate that the list of matches\n",
    "    is equal to the expected list of matches. Also allows plotting the first match instance.\n",
    "\n",
    "    Args:\n",
    "        input_graph (DiGraph): A graph\n",
    "        LHS (str): A pattern string\n",
    "        expected (list[dict]): The list of expected matches (as mappings from pattern nodes to input graph nodes)\n",
    "        collection_expected (list[dict]): The list of expected collection matches (as mappings from pattern nodes to corresponding collections)\n",
    "        plot (bool, optional): If True, plots the first match instance on the input graph (in red). Defaults to False.\n",
    "    \"\"\"\n",
    "    # Convert the pattern to a NetworkX graph + an extended condition function\n",
    "    pattern, collections_pattern, condition = lhs_to_graph(LHS, condition)\n",
    "    matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "    assert all([match.mapping in expected for match in matches]) and len(matches) == len(expected)\n",
    "    if plot and len(matches) > 0:\n",
    "        match = matches[0]\n",
    "        mapping = match.mapping\n",
    "        hl_nodes = {mapping[node] for node in pattern.nodes() if not is_anonymous_node(node)}\n",
    "        hl_edges = {(mapping[s], mapping[t]) for s, t in pattern.edges() if not (is_anonymous_node(s) or is_anonymous_node(t))}\n",
    "        print(f\"Plotting the match: {mapping}\")\n",
    "        draw_match(input_graph,match)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with simple cases, which do not take attributes into account at all. Consider the following quite-generic input graph (in which we will try to find matches for different patterns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBCiJdCkJbIkIKIl0KQ1siQwoiXQpEWyJECiJdCkEgLS0+IEIKQSAtLT4gQwpBIC0tPiBBCkMgLS0+IEMK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_graph = _create_graph(\n",
    "    ['A','B','C','D'], \n",
    "    [\n",
    "        ('A', 'B'),\n",
    "        ('A', 'C'),\n",
    "        ('A', 'A'),\n",
    "        ('C', 'C'),\n",
    "    ]\n",
    ")\n",
    "draw(input_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following tests, we try to match different patterns and make sure that the matcher found all of the possible matches. The first match in the list will be highlighted in the input graph (nodes and edges are colored in red), and printed above the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': 'C'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBCiJdCkJbIkIKIl0KQ1siQygxKQoiXQpzdHlsZSBDIHN0cm9rZTpyZWQsc3Ryb2tlLXdpZHRoOjRweDsKRFsiRAoiXQpBIC0tPiBCCkEgLS0+IEMKQSAtLT4gQQpDIC0tPiBDCmxpbmtTdHlsZSAzIHN0cm9rZTpyZWQsc3Ryb2tlLXdpZHRoOjRweDsK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Match all nodes 1 with self loops (both A and C)\n",
    "_assert_match(input_graph, \"1->1\", [{'1': 'A'}, {'1': 'C'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': 'C', '2': 'B'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBCiJdCkJbIkIoMikKIl0Kc3R5bGUgQiBzdHJva2U6cmVkLHN0cm9rZS13aWR0aDo0cHg7CkNbIkMoMSkKIl0Kc3R5bGUgQyBzdHJva2U6cmVkLHN0cm9rZS13aWR0aDo0cHg7CkRbIkQKIl0KQSAtLT4gQgpBIC0tPiBDCkEgLS0+IEEKQyAtLT4gQwpsaW5rU3R5bGUgMyBzdHJva2U6cmVkLHN0cm9rZS13aWR0aDo0cHg7Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all pairs of nodes 1, 2 where 1 has a self loop \n",
    "_assert_match(input_graph, '1->1, 2', [{'1': 'A', '2': 'B'}, {'1': 'A', '2': 'C'}, {'1': 'A', '2': 'D'}, \n",
    "                                    {'1': 'C', '2': 'A'}, {'1': 'C', '2': 'B'}, {'1': 'C', '2': 'D'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': 'A', '2': 'C'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBKDEpCiJdCnN0eWxlIEEgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpCWyJCCiJdCkNbIkMoMikKIl0Kc3R5bGUgQyBzdHJva2U6cmVkLHN0cm9rZS13aWR0aDo0cHg7CkRbIkQKIl0KQSAtLT4gQgpBIC0tPiBDCmxpbmtTdHlsZSAxIHN0cm9rZTpyZWQsc3Ryb2tlLXdpZHRoOjRweDsKQSAtLT4gQQpsaW5rU3R5bGUgMiBzdHJva2U6cmVkLHN0cm9rZS13aWR0aDo0cHg7CkMgLS0+IEMK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_assert_match(input_graph, '1->1, 1->2', [{'1': 'A', '2': 'B'}, {'1': 'A', '2': 'C'}]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'1': 'C', '2': 'A'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpBWyJBKDIpCiJdCnN0eWxlIEEgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpCWyJCCiJdCkNbIkMoMSkKIl0Kc3R5bGUgQyBzdHJva2U6cmVkLHN0cm9rZS13aWR0aDo0cHg7CkRbIkQKIl0KQSAtLT4gQgpBIC0tPiBDCmxpbmtTdHlsZSAxIHN0cm9rZTpyZWQsc3Ryb2tlLXdpZHRoOjRweDsKQSAtLT4gQQpDIC0tPiBDCmxpbmtTdHlsZSAzIHN0cm9rZTpyZWQsc3Ryb2tlLXdpZHRoOjRweDsK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_assert_match(input_graph, '1->1, 2->1', [{'1': 'C', '2': 'A'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a circle in the graph + self loop. There is no such match in the graph\n",
    "_assert_match(input_graph, '1->1, 2->1->2', []) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find five different nodes (the different pattern names enforce it).\n",
    "# There are only 4 nodes in the input graph, and so there are no matches.\n",
    "_assert_match(input_graph, '1,2,3,4,5', []) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to check more advanced features of both the parser and the matcher:\n",
    "* Checking for attributes (existance only)\n",
    "* Checking for attributes (match the values as well, using the parser-generated condition function)\n",
    "* Add user conditions\n",
    "* Anonymous nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a new input graph, which shows the connections between students and the courses they took throughout their degree:\n",
    "* Each node in the graph is associated with either a student or a course (and has an attribute \"type\" to denote which is which).\n",
    "* A student is defined by his/her name. Some students (not all of them) also metion their faculty.\n",
    "* A course is defined by its name. Some courses mention their associated number of units.\n",
    "* An edge from a student to a course denotes that the student took the course. It mentions the semester in which the student took the course.\n",
    "* An edge from a course to another course denotes that the first must be taken before the latter.\n",
    "\n",
    "The graph looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpBbGdvWyJBbGdvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KQUlbIkFJCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KTkxQWyJOTFAKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpEQlsiREIKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpCaW9bIkJpbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkpvaG4gLS0+fCJzZW09MyJ8IEJpbwpMdWN5IC0tPnwic2VtPTUifCBBbGdvCkx1Y3kgLS0+fCJzZW09NyJ8IEFJCkFteSAtLT58InNlbT01InwgQWxnbwpBbGdvIC0tPiBBSQpBSSAtLT4gTkxQCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_graph = _create_graph(\n",
    "    [\n",
    "        # Names\n",
    "        ('John', {'type': 'student', 'faculty': 'Biology'}),\n",
    "        ('Lucy', {'type': 'student', 'fauclty': 'CS'}),\n",
    "        ('Amy', {'type': 'student'}),\n",
    "        # Courses\n",
    "        ('Algo', {'type': 'course', 'units': 3}),\n",
    "        ('AI', {'type': 'course', 'units': 3}),\n",
    "        ('NLP', {'type': 'course', 'units': 5}),\n",
    "        ('DB', {'type': 'course'}),\n",
    "        ('Bio', {'type': 'course'})\n",
    "    ], \n",
    "    [\n",
    "        # Students take\n",
    "        ('John', 'Bio', {'sem': 3}),\n",
    "        ('Lucy', 'Algo', {'sem': 5}),\n",
    "        ('Lucy', 'AI', {'sem': 7}),\n",
    "        ('Amy', 'Algo', {'sem': 5}),\n",
    "        # KDAM\n",
    "        ('Algo', 'AI'),\n",
    "        ('AI', 'NLP'),\n",
    "    ]\n",
    ")\n",
    "draw(input_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now run some useful queries by matching patterns in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': 'Amy'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteShzKQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpzdHlsZSBBbXkgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpBbGdvWyJBbGdvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KQUlbIkFJCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KTkxQWyJOTFAKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpEQlsiREIKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpCaW9bIkJpbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkpvaG4gLS0+fCJzZW09MyJ8IEJpbwpMdWN5IC0tPnwic2VtPTUifCBBbGdvCkx1Y3kgLS0+fCJzZW09NyJ8IEFJCkFteSAtLT58InNlbT01InwgQWxnbwpBbGdvIC0tPiBBSQpBSSAtLT4gTkxQCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all students\n",
    "_assert_match(input_graph, 's[type=\"student\"]', [{'s': student} for student in ['Amy', 'John', 'Lucy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'c': 'DB'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpBbGdvWyJBbGdvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KQUlbIkFJCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KTkxQWyJOTFAKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpEQlsiREIoYykKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpzdHlsZSBEQiBzdHJva2U6cmVkLHN0cm9rZS13aWR0aDo0cHg7CkJpb1siQmlvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KSm9obiAtLT58InNlbT0zInwgQmlvCkx1Y3kgLS0+fCJzZW09NSJ8IEFsZ28KTHVjeSAtLT58InNlbT03InwgQUkKQW15IC0tPnwic2VtPTUifCBBbGdvCkFsZ28gLS0+IEFJCkFJIC0tPiBOTFAK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all courses\n",
    "_assert_match(input_graph, 'c[type=\"course\"]', [{'c': course} for course in ['DB','NLP','AI','Algo','Bio']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': 'Amy'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteShzKQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpzdHlsZSBBbXkgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpBbGdvWyJBbGdvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KQUlbIkFJCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KTkxQWyJOTFAKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpEQlsiREIKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpCaW9bIkJpbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkpvaG4gLS0+fCJzZW09MyJ8IEJpbwpMdWN5IC0tPnwic2VtPTUifCBBbGdvCkx1Y3kgLS0+fCJzZW09NyJ8IEFJCkFteSAtLT58InNlbT01InwgQWxnbwpBbGdvIC0tPiBBSQpBSSAtLT4gTkxQCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all students that took some course (all of them)\n",
    "_assert_match(input_graph, 's[type=\"student\"]->_[type=\"course\"]', [{'s': 'Amy'}, {'s': 'John'}, {'s': 'Lucy'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': 'Amy'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteShzKQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpzdHlsZSBBbXkgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpBbGdvWyJBbGdvCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KQUlbIkFJCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0KTkxQWyJOTFAKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpEQlsiREIKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpCaW9bIkJpbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkpvaG4gLS0+fCJzZW09MyJ8IEJpbwpMdWN5IC0tPnwic2VtPTUifCBBbGdvCkx1Y3kgLS0+fCJzZW09NyJ8IEFJCkFteSAtLT58InNlbT01InwgQWxnbwpBbGdvIC0tPiBBSQpBSSAtLT4gTkxQCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all students that took some 3-units course\n",
    "_assert_match(input_graph, 's[type=\"student\"]->_[type=\"course\", units=3]', [{'s': 'Amy'}, {'s': 'Lucy'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': 'Amy', 'c': 'Algo'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteShzKQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpzdHlsZSBBbXkgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpBbGdvWyJBbGdvKGMpCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0Kc3R5bGUgQWxnbyBzdHJva2U6cmVkLHN0cm9rZS13aWR0aDo0cHg7CkFJWyJBSQp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCk5MUFsiTkxQCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz01Il0KREJbIkRCCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KQmlvWyJCaW8KdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpKb2huIC0tPnwic2VtPTMifCBCaW8KTHVjeSAtLT58InNlbT01InwgQWxnbwpMdWN5IC0tPnwic2VtPTcifCBBSQpBbXkgLS0+fCJzZW09NSJ8IEFsZ28KbGlua1N0eWxlIDMgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpBbGdvIC0tPiBBSQpBSSAtLT4gTkxQCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all students that took some 3-units course, and the associated courses\n",
    "_assert_match(input_graph, 's[type=\"student\"]->c[type=\"course\", units=3]', [\n",
    "    {'s': 'Amy', 'c': 'Algo'}, {'s': 'Lucy', 'c': 'Algo'}, {'s': 'Lucy', 'c': 'AI'}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': 'Lucy', 'c1': 'Algo', 'c2': 'AI'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeShzKQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpzdHlsZSBMdWN5IHN0cm9rZTpyZWQsc3Ryb2tlLXdpZHRoOjRweDsKQW15WyJBbXkKdHlwZT0jcXVvdDtzdHVkZW50I3F1b3Q7Il0KQWxnb1siQWxnbyhjMSkKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTMiXQpzdHlsZSBBbGdvIHN0cm9rZTpyZWQsc3Ryb2tlLXdpZHRoOjRweDsKQUlbIkFJKGMyKQp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCnN0eWxlIEFJIHN0cm9rZTpyZWQsc3Ryb2tlLXdpZHRoOjRweDsKTkxQWyJOTFAKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpEQlsiREIKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpCaW9bIkJpbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkpvaG4gLS0+fCJzZW09MyJ8IEJpbwpMdWN5IC0tPnwic2VtPTUifCBBbGdvCmxpbmtTdHlsZSAxIHN0cm9rZTpyZWQsc3Ryb2tlLXdpZHRoOjRweDsKTHVjeSAtLT58InNlbT03InwgQUkKbGlua1N0eWxlIDIgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpBbXkgLS0+fCJzZW09NSJ8IEFsZ28KQWxnbyAtLT4gQUkKQUkgLS0+IE5MUAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all students which took two courses (and the courses) \n",
    "_assert_match(input_graph, 's[type=\"student\"]->c1[type=\"course\"], s->c2[type=\"course\"]', [ \n",
    "    {'s': 'Lucy', 'c1': 'AI', 'c2': 'Algo'},\n",
    "    {'s': 'Lucy', 'c1': 'Algo', 'c2': 'AI'}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'c1': 'Algo', 'c2': 'AI', 'c3': 'NLP'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpBbXlbIkFteQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDsiXQpBbGdvWyJBbGdvKGMxKQp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCnN0eWxlIEFsZ28gc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpBSVsiQUkoYzIpCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz0zIl0Kc3R5bGUgQUkgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpOTFBbIk5MUChjMykKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDssIHVuaXRzPTUiXQpzdHlsZSBOTFAgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpEQlsiREIKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpCaW9bIkJpbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OyJdCkpvaG4gLS0+fCJzZW09MyJ8IEJpbwpMdWN5IC0tPnwic2VtPTUifCBBbGdvCkx1Y3kgLS0+fCJzZW09NyJ8IEFJCkFteSAtLT58InNlbT01InwgQWxnbwpBbGdvIC0tPiBBSQpsaW5rU3R5bGUgNCBzdHJva2U6cmVkLHN0cm9rZS13aWR0aDo0cHg7CkFJIC0tPiBOTFAKbGlua1N0eWxlIDUgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4Owo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all tripltes c1, c2, c3 of courses such that c1 is a prerequisite of c2, and the same for c2 and c3\n",
    "_assert_match(input_graph, 'c1[type=\"course\"]->c2[type=\"course\"]->c3[type=\"course\"]', [\n",
    "    {'c1': 'Algo', 'c2': 'AI', 'c3': 'NLP'}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': 'Lucy'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0KTHVjeVsiTHVjeShzKQp0eXBlPSNxdW90O3N0dWRlbnQjcXVvdDssIGZhdWNsdHk9I3F1b3Q7Q1MjcXVvdDsiXQpzdHlsZSBMdWN5IHN0cm9rZTpyZWQsc3Ryb2tlLXdpZHRoOjRweDsKQW15WyJBbXkKdHlwZT0jcXVvdDtzdHVkZW50I3F1b3Q7Il0KQWxnb1siQWxnbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCkFJWyJBSQp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCk5MUFsiTkxQCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz01Il0KREJbIkRCCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KQmlvWyJCaW8KdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpKb2huIC0tPnwic2VtPTMifCBCaW8KTHVjeSAtLT58InNlbT01InwgQWxnbwpMdWN5IC0tPnwic2VtPTcifCBBSQpBbXkgLS0+fCJzZW09NSJ8IEFsZ28KQWxnbyAtLT4gQUkKQUkgLS0+IE5MUAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all students that took a course in their 7th semester\n",
    "_assert_match(input_graph, 's[type=\"student\"]-[sem=7]->_[type=\"course\"]', [ \n",
    "    {'s': 'Lucy'}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the match: {'s': 'John', 'c': 'Bio'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpKb2huWyJKb2huKHMpCnR5cGU9I3F1b3Q7c3R1ZGVudCNxdW90OywgZmFjdWx0eT0jcXVvdDtCaW9sb2d5I3F1b3Q7Il0Kc3R5bGUgSm9obiBzdHJva2U6cmVkLHN0cm9rZS13aWR0aDo0cHg7Ckx1Y3lbIkx1Y3kKdHlwZT0jcXVvdDtzdHVkZW50I3F1b3Q7LCBmYXVjbHR5PSNxdW90O0NTI3F1b3Q7Il0KQW15WyJBbXkKdHlwZT0jcXVvdDtzdHVkZW50I3F1b3Q7Il0KQWxnb1siQWxnbwp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCkFJWyJBSQp0eXBlPSNxdW90O2NvdXJzZSNxdW90OywgdW5pdHM9MyJdCk5MUFsiTkxQCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7LCB1bml0cz01Il0KREJbIkRCCnR5cGU9I3F1b3Q7Y291cnNlI3F1b3Q7Il0KQmlvWyJCaW8oYykKdHlwZT0jcXVvdDtjb3Vyc2UjcXVvdDsiXQpzdHlsZSBCaW8gc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpKb2huIC0tPnwic2VtPTMifCBCaW8KbGlua1N0eWxlIDAgc3Ryb2tlOnJlZCxzdHJva2Utd2lkdGg6NHB4OwpMdWN5IC0tPnwic2VtPTUifCBBbGdvCkx1Y3kgLS0+fCJzZW09NyJ8IEFJCkFteSAtLT58InNlbT01InwgQWxnbwpBbGdvIC0tPiBBSQpBSSAtLT4gTkxQCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all students that took a course before their 5th semester (use user-defined condition)\n",
    "_assert_match(input_graph, 's[type=\"student\"]-[sem]->c[type=\"course\"]', [\n",
    "    {'s': 'John', 'c': 'Bio'}\n",
    "], condition=lambda match: match['s->c']['sem'] < 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POC For Large Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POC: High number of nodes, solved with attribute filtering\n",
    "num_nodes = 100000\n",
    "\n",
    "input_graph = _create_graph(\n",
    "    [n for n in range(num_nodes)] + [(num_nodes+1, {'attr': 15}), (num_nodes+2, {'attr': 15})], \n",
    "    [\n",
    "        (num_nodes+1, num_nodes+2),\n",
    "        (2,4),\n",
    "        (3,1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "_assert_match(input_graph, 'X[attr]->Y[attr]', [{'X': num_nodes+1, 'Y': num_nodes+2}], plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collections Feature - Matcher Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgoxWyIxCnZhbD0xIl0KMlsiMgp2YWw9MiJdCjNbIjMKdmFsPTMiXQo0WyI0CnZhbD00Il0KNVsiNQp2YWw9NSJdCjEgLS0+IDIKMSAtLT4gMwozIC0tPiA0CjMgLS0+IDUK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = _create_graph(\n",
    "    [('1', {'val': 1}), ('2', {'val': 2}), ('3', {'val': 3}), ('4',{'val': 4}), ('5',{'val': 5})],\n",
    "    [('1','2'), ('1','3'), ('3','4'), ('3','5')]\n",
    ")\n",
    "draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Ensuring that in a case where we match all modes, and collect all nodes (with no specific connection to the match), \n",
    "there's actually will be a collection of all nodes for each match \n",
    "\"\"\"\n",
    "\n",
    "input_graph = g.copy()\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x;y')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "last_x = []\n",
    "for match in matches:    \n",
    "    assert match['x'] not in last_x\n",
    "    assert match.collection_mapping == {'y': {'4', '5', '1', '3', '2'}}\n",
    "    last_x.append(match['x'])\n",
    "assert len(matches) == 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Ensuring that:\n",
    "1.⁠ ⁠We get four matches based on the pattern\n",
    "2.⁠ ⁠We ensure the collection for each is correct\n",
    "\"\"\"\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x->y;x->z')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "for match in matches:\n",
    "    assert match.mapping in [{'x': '1', 'y': '3'}, {'x': '1', 'y': '2'}, {'x': '3', 'y': '5'}, {'x': '3', 'y': '4'}]\n",
    "    if (match['x']['val'] == 1):\n",
    "        assert match.collection_mapping == {'z': {'3', '2'}}\n",
    "    else:\n",
    "        assert match['x']['val'] == 3\n",
    "        assert match.collection_mapping == {'z': {'5', '4'}}\n",
    "assert len(matches) == 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "Ensuring that:\n",
    "1.⁠ ⁠We get four matches based on the pattern\n",
    "2.⁠ ⁠For each match, there is an empty collection for (x,z), z, (z,y)\n",
    "#TODO: No matches at all! no empty collections\n",
    "\"\"\"\n",
    "\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x->y;x->z->y')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "#for match in matches:\n",
    "#        assert match.mapping in [{'x': '1', 'y': '3'}, {'x': '1', 'y': '2'}, {'x': '3', 'y': '5'}, {'x': '3', 'y': '4'}]\n",
    "#        assert match.collection_mapping == {}\n",
    "assert len(matches) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Ensuring that:\n",
    "1.⁠ ⁠We get two matches based on the pattern\n",
    "2.⁠ ⁠For each match, the collections are created correctly - they all should be empty\n",
    "#TODO: No matches at all! no empty collections\n",
    "\"\"\"\n",
    "\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x->y->z;x->a->b->c')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "#for match in matches:\n",
    "#        assert match.mapping in [{'x': '1', 'y': '3', 'z': '5'}, {'x': '1', 'y': '3', 'z': '4'}]\n",
    "#        assert match.collection_mapping == {}\n",
    "assert len(matches) == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Ensuring that:\n",
    "1.⁠ ⁠We get two matches based on the pattern\n",
    "2.⁠ ⁠For each match, the collections are created correctly - they all should be empty\n",
    "#TODO: No matches at all! no empty collections\n",
    "\"\"\"\n",
    "\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x->y->z;x->a,a->b,b->c')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "#for match in matches:\n",
    "#        assert match.mapping in [{'x': '1', 'y': '3', 'z': '5'}, {'x': '1', 'y': '3', 'z': '4'}]\n",
    "#        assert match.collection_mapping == {}\n",
    "assert len(matches) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Ensuring that:\n",
    "1.⁠ ⁠We get two matches based on the pattern\n",
    "2.⁠ ⁠For each match, the collections are created correctly - they all should be empty\n",
    "#TODO: No matches at all! no empty collections\n",
    "\"\"\"\n",
    "\n",
    "pattern, collections_pattern, condition = lhs_to_graph('x->y->z;x->a,a->b,z->c')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "#for match in matches:\n",
    "#        assert match.mapping in [{'x': '1', 'y': '3', 'z': '5'}, {'x': '1', 'y': '3', 'z': '4'}]\n",
    "#        assert match.collection_mapping == {}\n",
    "assert len(matches) == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgoxWyIxCnZhbD0xIl0KMlsiMgp2YWw9MiJdCjNbIjMKdmFsPTMiXQo0WyI0CnZhbD00Il0KNVsiNQp2YWw9NSJdCjEgLS0+IDIKMSAtLT4gMwozIC0tPiA0CjMgLS0+IDUK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = _create_graph(\n",
    "    [('1', {'val': 1}), ('2', {'val': 2}), ('3', {'val': 3}), ('4',{'val': 4}), ('5',{'val': 5})],\n",
    "    [('1','2'), ('1','3'), ('3','4'), ('3','5')]\n",
    ")\n",
    "draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': '3', 'y': '5'} {'z': {'4', '5'}}\n"
     ]
    }
   ],
   "source": [
    "pattern, collections_pattern, condition = lhs_to_graph('x[val];x[val]->y[val]->z[val]')\n",
    "matches = [match for match in find_matches(input_graph, pattern, collections_pattern, condition=condition)]\n",
    "assert len(matches) == 1\n",
    "assert matches[0]['x']['val'] == 1\n",
    "assert matches[0].collection_mapping == {'y': {'3'}, 'z': {'4', '5'}}\n",
    "print(match.mapping, match.collection_mapping)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
