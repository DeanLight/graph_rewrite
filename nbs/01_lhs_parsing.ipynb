{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp lhs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lark\n",
      "  Using cached lark-1.1.5-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: lark\n",
      "Successfully installed lark-1.1.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "Installing collected packages: networkx\n",
      "Successfully installed networkx-3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install lark\n",
    "# %pip install networkx\n",
    "from lark import Lark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LHS parser ##\n",
    "\n",
    "parsing of the pattern sent as lhs, into a networkX graph representing the template to search.\n",
    "\n",
    "The module converts the declerative constraints regarding the properties of the nodes and edges in the LHS, to imperative functions that are checked together with the 'condition' parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#attributes: allow optional \\n here, for imperative syntax)\n",
    "#attribute: #[\"=\" value] \n",
    "\n",
    "#    attr_name: /[a-zA-Z0-9]+/ #TODO: lark-imported\n",
    "#    type:  \"int\" | \"string\" | \"bool\" #TODO: escaped string or word\n",
    "#    value: /[0-9a-zA-Z]/\n",
    "\n",
    "#    %import common.WS #CHANGE to allow \\n in the imperative option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/User/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "lhs_parser = Lark(r\"\"\"\n",
    "    %import common.NUMBER -> NATURAL_NUMBER \n",
    "    %import common.ESCAPED_STRING\n",
    "    %import common.WS \n",
    "    %ignore WS\n",
    "\n",
    "    NAMED_VERTEX: /[a-zA-Z0-9]+/ \n",
    "    ANONYMUS: \"_\"\n",
    "    ATTR_NAME: /[a-zA-Z0-9]+/ \n",
    "    TYPE:  \"int\" | \"string\" | \"bool\" \n",
    "    VALUE: /[0-9a-zA-Z]/\n",
    "\n",
    "    attribute: ATTR_NAME [\":\" TYPE] [\"=\" VALUE] \n",
    "    attributes: \"\\[\" attribute (\",\" attribute)* \"\\]\"\n",
    "\n",
    "    multi_connection: \"-\" NATURAL_NUMBER \"+\" [attributes] \"->\" \n",
    "                    | \"-\" NATURAL_NUMBER [attributes] \"->\" \n",
    "    connection: \"-\" [attributes \"-\"] \">\"\n",
    "              | multi_connection\n",
    "    \n",
    "    index_vertex: NAMED_VERTEX \"<\" NATURAL_NUMBER (\",\" NATURAL_NUMBER)* \">\"\n",
    "\n",
    "    vertex: NAMED_VERTEX [attributes]\n",
    "        | index_vertex [attributes]\n",
    "        | ANONYMUS [attributes]\n",
    "\n",
    "    pattern: vertex (connection vertex)*\n",
    "    patterns: pattern (\";\" pattern)*\n",
    "        \n",
    "    \"\"\", parser=\"lalr\", start='patterns' , debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = lhs_parser.parse(\"aaaaa->b\") #.pretty(indent_str = \" $ \")\n",
    "assert(tree != None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'patterns'), [Tree(Token('RULE', 'pattern'), [Tree(Token('RULE', 'vertex'), [Token('NAMED_VERTEX', 'aaaaa'), None]), Tree(Token('RULE', 'connection'), [None]), Tree(Token('RULE', 'vertex'), [Token('NAMED_VERTEX', 'b'), None])])])\n"
     ]
    }
   ],
   "source": [
    "# print(tree)\n",
    "# assert(tree == \n",
    "#     Tree(Token('RULE', 'patterns'),[\n",
    "#       Tree(Token('RULE', 'pattern'),[\n",
    "#         Tree(Token('RULE', 'vertex'),[\n",
    "#           Tree(Token('RULE', 'vertex'),[]),\n",
    "#           None\n",
    "#         ])\n",
    "#       ])\n",
    "#     ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "The transformer is designed to return the networkX graph representing the patterns.\n",
    "\n",
    "For each branch, the appropriate method will be called with the children of the branch as its argument, and its return value will replace the branch in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import itertools\n",
    "import copy\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "cnt:int = 0 # unique id for anonymous vertices\n",
    "from lark import Tree, Transformer\n",
    "class lhsTransformer(Transformer):\n",
    "    def NATURAL_NUMBER(self, number):\n",
    "        return int(number)\n",
    "    \n",
    "    def attribute(self, attr_name, _):\n",
    "        return (attr_name, \"default\") # constraints are handled in other transformer.\n",
    "    \n",
    "    def attributes(self, *attributes: list):\n",
    "        # return a packed list of the attribute names.\n",
    "        attr_dict = {}\n",
    "        for attribute in attributes:\n",
    "            attr_dict[attribute[0]] = attribute[1]\n",
    "        return attr_dict\n",
    "\n",
    "    def multi_connection(self, number, attributes: dict): # +\n",
    "        # renewed: return the list of attributes(strings), add a special attribute to denote number of duplications,\n",
    "        #   and FALSE (indicating that the connection is not deterministic)\n",
    "        attributes[\"$dup\"] = number\n",
    "        return (attributes, False)\n",
    "    \n",
    "    def multi_connection(self, number, attributes: dict): # no +\n",
    "        # renewed: return the list of attributes(strings), add a special attribute to denote number of duplications,\n",
    "        #   and TRUE (indicating that the connection is not deterministic)\n",
    "        attributes[\"$dup\"] = number\n",
    "        return (attributes, True)\n",
    "\n",
    "    def connection(self, multiconnection_params: tuple): #multiconnection\n",
    "        # return the packed list of attributes received, num_duplications, is_deterministic\n",
    "        return multiconnection_params\n",
    "\n",
    "    def connection(self, *attributes): #\n",
    "        # return the packed list of attributes received, num_duplications = 1, is_deterministic = True\n",
    "        attributes[\"$dup\"] = 1\n",
    "        return (attributes, True)\n",
    "\n",
    "    def ANONYMUS(self): #\n",
    "        # return a dedicated name for anonymus (string), and an empty list.\n",
    "        cnt += 1\n",
    "        return (\"$\" + str(cnt), [])\n",
    "\n",
    "    def index_vertex(self, main_name, *numbers):\n",
    "        # return the main name of the vertex, and a list of the indices specified.\n",
    "        return (main_name, numbers)\n",
    "    \n",
    "    def NAMED_VERTEX(self, name):\n",
    "        # return the main name of the vertex, and an empty list.\n",
    "        return (name, [])\n",
    "\n",
    "    def vertex(self, vertex_tuple: tuple, attributes: dict):\n",
    "        # return arguments\n",
    "        name, indices_list = vertex_tuple\n",
    "        new_name = \",\".join(indices_list) # numbers are strings, no convertion needed.\n",
    "        return (new_name, attributes)\n",
    "\n",
    "    def pattern(self, vertex, *rest):\n",
    "        # 1) unpack lists of vertices and connections.\n",
    "        conn, vertices = rest[::2], rest[1::2]\n",
    "        vertices.insert(0,vertex)\n",
    "        # 2) create a networkX graph:\n",
    "            # if there is a special attribute with TRUE, dumplicate the connection __number__ times.\n",
    "        G = nx.Graph()\n",
    "\n",
    "        # simplified vertion - ignore duplications\n",
    "        G.add_nodes_from(vertices)\n",
    "        edge_list = []\n",
    "        for i,edge in enumerate(conn):\n",
    "            edge_list.append((vertices[i], vertices[i+1], edge[0])) # ignore edge[1] - determinism flag\n",
    "\n",
    "        # more complex vertion - duplications\n",
    "        # create a recursive function that adds the vertices and edges, \n",
    "        # that calls itself by the number of duplications on each level.\n",
    "\n",
    "    def patterns(self,):\n",
    "        g = nx.Graph()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeView([(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import networkx as nx\n",
    "# H = nx.path_graph(10)\n",
    "# H.edges\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type and constant value checking\n",
    "The transformer is designed to collect the node type and constant node value constraints, such that they are added to the 'condition' parameter to be checked later.\n",
    "\n",
    "This transformer works on a copy of the tree to keep it intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class collectTypeConstraints(Transformer):\n",
    "    def attribute(self, attr_name, type, value):\n",
    "        # return a mapping from attr_name - > required type and value\n",
    "        pass\n",
    "\n",
    "    def attributes(self, *attributes):\n",
    "        # return a packed list of the attribute mappings.\n",
    "        pass\n",
    "\n",
    "    def vertex(self, name, indices_list, attributes_list):\n",
    "        # same as lhsTransformer\n",
    "        pass\n",
    "\n",
    "    def pattern(self, vertex, *connections_to_vertex):\n",
    "        # return arguments\n",
    "        pass\n",
    "\n",
    "    def patterns(self, *patterns):\n",
    "        # unpack lists of vertices and connections.\n",
    "        def typeCondition(Match):\n",
    "            # for every vertex in vertex list:\n",
    "                # create full_vertex_name by the attached indices list\n",
    "                # for every attr, type, name required for the vertex:\n",
    "                    # constructor = getName(type) - get the constructor for the type\n",
    "                    # 1) check that the required type and value match together.\n",
    "                    # try:\n",
    "                    #     instance = constructor(value)\n",
    "                    # Except:\n",
    "                        # flag = False: value does not match the type.\n",
    "\n",
    "                    # 2) check that the value constraint holds\n",
    "                    # if getattr(instance, __eq__) == None:\n",
    "                        # flag = False. the type must implement __eq__\n",
    "                    # if not (instance == match[full_vertex_name][attr])\n",
    "\n",
    "                    # no need to check the type constraint(?), if the value fits. (python)\n",
    "\n",
    "            # TODO: perform the same iterations in the connections list.\n",
    "\n",
    "            #return flag and condition(Match)\n",
    "            pass\n",
    "\n",
    "        return typeCondition #sent as a module output and replaces condition.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_lhs(lhs: string):\n",
    "    tree = lhs_parser.parse(lhs)\n",
    "    final_g = lhsTransformer().transform(tree) #networkx graph\n",
    "    return final_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_syntax =  \"\"\"\n",
    "a -> b\n",
    "\n",
    "a -[x:int = ...]-> b\n",
    "\n",
    "a -> b[x:int = ...]\n",
    "\n",
    "a -> b -6+[weight:int]-> c -> d[value:int]\n",
    "d<0> -> e\n",
    "d<5> -> e\n",
    "\n",
    "b -+-> d[value:int]\n",
    "d<0> -7-> e\n",
    "e<0,5> -> _\n",
    "\n",
    "b[ \\\n",
    "value: str = \\\"hello\\\", \\\n",
    "id: int \\\n",
    "]\n",
    "\n",
    "b -[\n",
    "...\n",
    "]-> c \n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae9660db38ac8643b5abe3ade23e36bb7e77026bbf1f37e511afc8ce3b66621b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
