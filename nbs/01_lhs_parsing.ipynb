{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| default_exp lhs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lark\n",
    "# %pip install networkx\n",
    "from lark import Lark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LHS parser ##\n",
    "\n",
    "parsing of the pattern sent as lhs, into a networkX graph representing the template to search.\n",
    "\n",
    "The module converts the declerative constraints regarding the properties of the nodes and edges in the LHS, to imperative functions that are checked together with the 'condition' parameter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "lhs_parser = Lark(r\"\"\"\n",
    "    %import common.INT -> INT \n",
    "    %import common.FLOAT -> FLOAT\n",
    "    %import common.ESCAPED_STRING -> STRING\n",
    "    %import common.WS -> WS\n",
    "    %ignore WS\n",
    "\n",
    "    NAMED_VERTEX: /[a-zA-Z0-9]+/\n",
    "    ANONYMUS: \"_\"\n",
    "    ATTR_NAME: /[a-zA-Z0-9]+/\n",
    "    TYPE:  \"int\" | \"string\"\n",
    "    BOOLEAN: \"True\" | \"False\"\n",
    "    NATURAL_NUMBER: /[1-9][0-9]?/\n",
    "    INDEX: /[0-9]+/\n",
    "\n",
    "    value: FLOAT | STRING | INT | BOOLEAN\n",
    "\n",
    "    attribute: ATTR_NAME [\":\" TYPE] [\"=\" value]\n",
    "    attributes: \"[\" attribute (\",\" attribute)* \"]\"\n",
    "\n",
    "    multi_connection: \"-\" NATURAL_NUMBER [attributes] \"->\" \n",
    "    connection: [\"-\" attributes]\"->\"\n",
    "              | multi_connection\n",
    "    \n",
    "    index_vertex: NAMED_VERTEX \"<\" INDEX (\",\" INDEX)* \">\"\n",
    "\n",
    "    vertex: NAMED_VERTEX [attributes]\n",
    "    | index_vertex [attributes]\n",
    "    | ANONYMUS [attributes]\n",
    "\n",
    "    pattern: vertex (connection vertex)*\n",
    "    patterns: pattern (\";\" pattern)*\n",
    "\n",
    "    \"\"\", parser=\"lalr\", start='patterns' , debug=True)\n",
    "\n",
    "# multi_connection: \"-\" NATURAL_NUMBER \"+\" [attributes] \"->\"  - setting for the \"-num+->\" feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "The transformer is designed to return the networkX graph representing the patterns.\n",
    "\n",
    "For each branch, the appropriate method will be called with the children of the branch as its argument, and its return value will replace the branch in the tree.\n",
    "\n",
    "The secondary task of the transformer is to collect the node/edge type and constant node/edge value constraints, such that they are added to the 'condition' parameter to be checked later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import itertools\n",
    "import copy\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "cnt:int = 0 # unique id for anonymous vertices\n",
    "from lark import Tree, Transformer\n",
    "class lhsTransformer(Transformer):\n",
    "    def __init__(self, visit_tokens: bool = True) -> None:\n",
    "        super().__init__(visit_tokens)\n",
    "        self.constraints = {}\n",
    "        self.cnt = 0\n",
    "\n",
    "    def STRING(self, arg):\n",
    "        return arg[1:-1] # remove \" \"\n",
    "    \n",
    "    def BOOLEAN(self, arg):\n",
    "        return bool(arg)\n",
    "    \n",
    "    def INT(self, arg): # can be negative\n",
    "        return int(arg)\n",
    "    \n",
    "    def FLOAT(self, arg):\n",
    "        return float(arg)\n",
    "    \n",
    "    def NATURAL_NUMBER(self, number): # for duplications\n",
    "        return int(number)\n",
    "    \n",
    "    def value(self, args): # one argument encased in a list\n",
    "        return args[0]\n",
    "    \n",
    "    def attribute(self, args): #(attr_name, *rest):\n",
    "        # if an optional token was not parsed, None is placed in the parse tree.\n",
    "        attr_name, type, value = args\n",
    "        # pass a tuple of attr_name, required type, required value.\n",
    "        return (attr_name, type, value) # constraints are handled in other transformer.\n",
    "    \n",
    "    def attributes(self, attributes): # a list of triples \n",
    "        # return a packed list of the attribute names.\n",
    "        attr_names, constraints = {}, {}\n",
    "        for attribute in attributes:\n",
    "            attr_names[str(attribute[0])] = None # will be added to the graph itself\n",
    "            constraints[str(attribute[0])] = (attribute[1], attribute[2]) # will be added to the condition function\n",
    "        print(\"constraints found on: \" + str(constraints.keys()))\n",
    "        return (attr_names, constraints)\n",
    "\n",
    "    def multi_connection(self, args): # +\n",
    "        # return the list of attributes(strings), add a special attribute to denote number of duplications.\n",
    "        #   for \"-+->\" implementation also return FALSE if \"+\" is parsed (indicating that the connection is not deterministic)\n",
    "        number, attributes = args\n",
    "        if attributes == None:\n",
    "            attributes = ({},{})\n",
    "        attributes[0][\"$dup\"] = number # removed in graph construction\n",
    "        return attributes\n",
    "\n",
    "    def connection(self, attributes): # (dict of attributes, constraints: attribute -> (val,type))\n",
    "        # return the packed list of attributes received, num_duplications = 1, is_deterministic = True\n",
    "        attributes = attributes[0]\n",
    "        if attributes == None:\n",
    "            attributes = ({},{})\n",
    "        attributes[0][\"$dup\"] = 1\n",
    "        return (attributes, True)\n",
    "\n",
    "    def ANONYMUS(self): #\n",
    "        # return a dedicated name for anonymus (string), and an empty list.\n",
    "        x = (\"$\" + str(cnt), [])\n",
    "        self.cnt += 1\n",
    "        return x\n",
    "\n",
    "    def index_vertex(self, args):\n",
    "        # return the main name of the vertex, and a list of the indices specified.\n",
    "        main_name_tup, *numbers = args #numbers is a list\n",
    "        return (main_name_tup[0], list(numbers))\n",
    "    \n",
    "    def NAMED_VERTEX(self, name):\n",
    "        # return the main name of the vertex, and an empty list.\n",
    "        return (name, [])\n",
    "\n",
    "    def vertex(self, args): # (vertex_tuple: tuple, attributes: list)\n",
    "        # return arguments\n",
    "        vertex_tuple, *attributes = args # attributes is a empty list/ a list containing a tuple: (names dict, constraints dict)\n",
    "        name, indices_list = vertex_tuple \n",
    "\n",
    "        if indices_list == None:\n",
    "            indices_list = []\n",
    "        indices = \",\".join([str(num) for num in indices_list])\n",
    "        new_name =  name + \"<\" + indices + \">\" if indices == [] else str(name) # numbers are strings, no convertion needed.\n",
    "        if attributes[0] == None:\n",
    "            return (new_name, {})\n",
    "        # now that we have the vertex name we add the attribute constraints:\n",
    "        # vertices may appear multiple times in LHS thus we unite the constraints. We assume there cannot be contradicting constraints.\n",
    "        attribute_names, constraints = attributes[0] # extract from list\n",
    "        # the second element of the tuple is the constraints dict: attr_name -> (value,type)\n",
    "        self.constraints[new_name] = {}\n",
    "        self.constraints[new_name] = self.constraints[new_name] | constraints \n",
    "        return (new_name, attribute_names) #(string, dict)\n",
    "\n",
    "    def pattern(self, args):\n",
    "        # 1) unpack lists of vertices and connections.\n",
    "        vertex, *rest = args\n",
    "        conn, vertices = list(rest)[::2], list(rest)[1::2]\n",
    "        vertices.insert(0,vertex)\n",
    "        # print(vertices)\n",
    "        # print(conn)\n",
    "        # 2) create a networkX graph:\n",
    "            # Future feature: if there is a special attribute with TRUE (deterministic), dumplicate the connection $dup times.\n",
    "        G = nx.DiGraph()\n",
    "\n",
    "        # simplified vertion - ignore duplications\n",
    "        G.add_nodes_from(vertices) # list of tuples \n",
    "        edge_list = []\n",
    "        for i,edge in enumerate(conn):\n",
    "            # for now the duplication feature is not included so we remove the $dup attribute\n",
    "            attribute_names, constraints = edge[0] # at worst will be {},{} since we handeled None in the connection rule.\n",
    "            attribute_names.pop(\"$dup\", 0)\n",
    "            edge_list.append((vertices[i][0], vertices[i+1][0], attribute_names)) # ignore edge[1] - determinism flag. edge[0] is the tuple of dicts of attributes.\n",
    "            # add constraints - we assume an edge only appears once in LHS\n",
    "            print(\"edges before filter: \" + str(constraints))\n",
    "            filtered_cons = dict(filter(lambda tup: not tup[1] == (None, None), constraints.items()))\n",
    "            print(\"edges after filter: \" + str(filtered_cons))\n",
    "            if filtered_cons: # not empty - there are concrete constraints\n",
    "                self.constraints[str(vertices[i]) + \"->\" + str(vertices[i+1])] = filtered_cons\n",
    "\n",
    "        # more complex vertion - duplications\n",
    "        # create a recursive function that adds the vertices and edges, \n",
    "        # that calls itself by the number of duplications on each level.\n",
    "        print(\"vertices: \" + str(vertices))\n",
    "        print(\"edges: \" + str(edge_list))\n",
    "        G.add_edges_from(edge_list)\n",
    "        return G\n",
    "\n",
    "    def patterns(self, args):\n",
    "        g, *graphs = args\n",
    "        graphs.insert(0,g)\n",
    "        # unite all the patterns into a single graph\n",
    "        G = nx.DiGraph()\n",
    "\n",
    "        combined_attributes = dict() # dict of dicts (node_name -> attribute -> None)\n",
    "        new_nodes = []\n",
    "        new_edges = []\n",
    "        for graph in graphs:\n",
    "            for node in graph.nodes:\n",
    "                combined_attributes[node] = {}\n",
    "                combined_attributes[node] = combined_attributes[node] | graph.nodes.data()[node]\n",
    "                new_nodes.append(node) #unite the dicts for each\n",
    "            for edge in graph.edges:\n",
    "                # we assumed edges cannot appear more than once in LHS\n",
    "                combined_attributes[edge[0] + \"->\" + edge[1]] = graph.edges[edge[0],edge[1]]\n",
    "                new_edges.append(edge)\n",
    "        # filtered_attr = dict(filter(lambda _,value: not value == (None, None), combined_attributes.items()))\n",
    "        G.add_nodes_from([(node, combined_attributes[node]) for node in new_nodes])\n",
    "        G.add_edges_from([(node1, node2, combined_attributes[node1 + \"->\" + node2]) for (node1,node2) in new_edges])\n",
    "\n",
    "        return (G, copy.deepcopy(self.constraints)) #sent as a module output and replaces condition."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from graph_rewrite.match_class import Match\n",
    "def lhs_to_graph(lhs: str, condition):\n",
    "    \"\"\"Given an LHS pattern and a condition function, return the directed graph represented by the pattern, \n",
    "    along with an updated condition function that combines the original constraints and the new value and type constraints\n",
    "    deriving from the pattern.\n",
    "\n",
    "    Args:\n",
    "        lhs (string): A string in lhs format \n",
    "        condition (lambda: Match -> bool): A function supplied by the user specifying additional \n",
    "                                           constraints on the graph components.\n",
    "\n",
    "    Returns:\n",
    "        DiGraph, lambda: Match->bool: a networkx graph that is the graph represented by the pattern, \n",
    "                                      and an extended condition function as mentioned above.\n",
    "    \"\"\"\n",
    "    tree = lhs_parser.parse(lhs)\n",
    "    final_graph, constraints = lhsTransformer().transform(tree)\n",
    "    # constraints is a dictionary: vertex/edge -> {attr_name: (value, type), ...}\n",
    "\n",
    "    # add the final constraints to the \"condition\" function\n",
    "    def type_condition(match: Match):\n",
    "        flag = True\n",
    "        for graph_obj in constraints.keys():\n",
    "            obj_constraints = constraints[graph_obj]\n",
    "            for attr_name in obj_constraints.keys():\n",
    "                required_type, required_value = obj_constraints[attr_name]\n",
    "\n",
    "                # check value constraint\n",
    "                if required_value != None:\n",
    "                    if not hasattr(required_value, '__eq__') or (not required_value == match[v][attr_name]):\n",
    "                        flag = False\n",
    "                \n",
    "                # check type constraint only of value was not checked\n",
    "                elif required_type != None and not isinstance(match[v][attr_name], required_type):\n",
    "                    flag = False\n",
    "\n",
    "        return flag and condition(match) # True <=> the match satisfies all the constraints.\n",
    "            \n",
    "    return final_graph, type_condition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_rewrite.core import _create_graph, _plot_graph\n",
    "\n",
    "def _graphs_equal(graph1, graph2):  \n",
    "    # Compare node attributes\n",
    "    for node in graph1.nodes():\n",
    "        if node not in graph2.nodes():\n",
    "            return False\n",
    "\n",
    "        attributes1 = graph1.nodes[node]\n",
    "        attributes2 = graph2.nodes[node]\n",
    "\n",
    "        if attributes1 != attributes2:\n",
    "            return False\n",
    "\n",
    "    # Compare edge attributes\n",
    "    for edge in graph1.edges():\n",
    "        if edge not in graph2.edges():\n",
    "            return False\n",
    "\n",
    "        attributes1 = graph1.edges[edge]\n",
    "        attributes2 = graph2.edges[edge]\n",
    "\n",
    "        if attributes1 != attributes2:\n",
    "            return False\n",
    "        \n",
    "    # Compare graph structures\n",
    "    #graph_structure_equal = nx.is_isomorphic(graph1, graph2)\n",
    "    return True\n",
    "\n",
    "    # Check if the graphs are equal\n",
    "    # return (\n",
    "    #     graph1.adj == graph2.adj\n",
    "    #     and graph1.graph == graph2.graph \n",
    "    # )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertices: [('a', {})]\n",
      "edges: []\n",
      "edges before filter: {}\n",
      "edges after filter: {}\n",
      "vertices: [('a', {}), ('b', {})]\n",
      "edges: [('a', 'b', {})]\n",
      "edges before filter: {}\n",
      "edges after filter: {}\n",
      "vertices: [('a', {}), ('b', {})]\n",
      "edges: [('a', 'b', {})]\n",
      "edges before filter: {}\n",
      "edges after filter: {}\n",
      "edges before filter: {}\n",
      "edges after filter: {}\n",
      "vertices: [('a', {}), ('b', {}), ('c', {})]\n",
      "edges: [('a', 'b', {}), ('b', 'c', {})]\n",
      "edges before filter: {}\n",
      "edges after filter: {}\n",
      "edges before filter: {}\n",
      "edges after filter: {}\n",
      "vertices: [('a', {}), ('b', {}), ('a', {})]\n",
      "edges: [('a', 'b', {}), ('b', 'a', {})]\n"
     ]
    }
   ],
   "source": [
    "condition = lambda x: True\n",
    "res, _ = lhs_to_graph(\"a\", condition)\n",
    "expected = _create_graph(['a'], [])\n",
    "assert(_graphs_equal(expected, res))\n",
    "#_plot_graph(res)\n",
    "\n",
    "res, _ = lhs_to_graph(\"a->b\", condition)\n",
    "expected = _create_graph(['a','b'], [('a','b')])\n",
    "assert(_graphs_equal(expected, res))\n",
    "#_plot_graph(res)\n",
    "\n",
    "res, _ = lhs_to_graph(\"a -> b\", condition)\n",
    "expected = _create_graph(['a','b'], [('a','b')])\n",
    "assert(_graphs_equal(expected, res))\n",
    "#_plot_graph(res)\n",
    "\n",
    "res, _ = lhs_to_graph(\"a->b -> c\", condition)\n",
    "expected = _create_graph(['a','b','c'], [('a','b'),('b','c')])\n",
    "assert(_graphs_equal(expected, res))\n",
    "#_plot_graph(res)\n",
    "\n",
    "res, _ = lhs_to_graph(\"a->b -> a\", condition)\n",
    "expected = _create_graph(['a','b'], [('a','b'),('b','a')])\n",
    "assert(_graphs_equal(expected, res))\n",
    "#_plot_graph(res)\n",
    "\n",
    "#ANON"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraints found on: dict_keys(['x'])\n",
      "vertices: [('a', {'x': None})]\n",
      "edges: []\n",
      "constraints found on: dict_keys(['x'])\n",
      "edges before filter: {'x': (None, 5)}\n",
      "edges after filter: {'x': (None, 5)}\n",
      "vertices: [('a', {}), ('b', {})]\n",
      "edges: [('a', 'b', {'x': None})]\n",
      "constraints found on: dict_keys(['x', 'y'])\n",
      "vertices: [('a', {'x': None, 'y': None})]\n",
      "edges: []\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res, _ = lhs_to_graph(\"a[x=5]\", condition)\n",
    "expected = _create_graph([('a', {'x':None})], [])\n",
    "assert(_graphs_equal(expected, res))\n",
    "#_plot_graph(res)\n",
    "\n",
    "res, _ = lhs_to_graph(\"a-[x=5]->b\", condition)\n",
    "expected = _create_graph(['a', 'b'], [('a','b',{'x':None})])\n",
    "assert(_graphs_equal(expected, res))\n",
    "#_plot_graph(res)\n",
    "\n",
    "res, _ = lhs_to_graph(\"a<1,2>[x=5, y: int = 6]\", condition)\n",
    "expected = _create_graph([('a<1,2>',{'x':None, 'y':None})],[])\n",
    "#assert(_graphs_equal(res,expected))\n",
    "_plot_graph(res)\n",
    "\n",
    "# res = lhs_to_graph(\"a[a]->b[ b ] -> c[ c ]\")\n",
    "# expected = _create_graph(['a','b','c'], [('a','b'),('b','c')])\n",
    "# assert(_graphs_equal(expected, res))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = lhs_to_graph(\"a->b -> c; c-> d\")\n",
    "# expected = _create_graph(['a','b','c','d'], [('a','b'),('b','c'),('c','d')])\n",
    "# assert(_graphs_equal(expected, res))\n",
    "\n",
    "# res = lhs_to_graph(\"a->b -> c; d\")\n",
    "# expected = _create_graph(['a','b','c', 'd'], [('a','b'),('b','c')])\n",
    "# assert(_graphs_equal(expected, res))\n",
    "\n",
    "# res = lhs_to_graph(\"a->b -> c; c[x=5]\")\n",
    "# expected = _create_graph(['a','b','c'], [('a','b'),('b','c')])\n",
    "# expected.nodes[\"c\"][\"x\"] = \"default\"\n",
    "# assert(_graphs_equal(expected, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required_syntax =  \"\"\"\n",
    "# a -> b\n",
    "\n",
    "# a -[x:int = ...]-> b\n",
    "\n",
    "# a -> b[x:int = ...]\n",
    "\n",
    "# a -> b -6+[weight:int]-> c -> d[value:int]\n",
    "# d<0> -> e\n",
    "# d<5> -> e\n",
    "\n",
    "# b -+-> d[value:int]\n",
    "# d<0> -7-> e\n",
    "# e<0,5> -> _\n",
    "\n",
    "# b[ \\\n",
    "# value: str = \\\"hello\\\", \\\n",
    "# id: int \\\n",
    "# ]\n",
    "\n",
    "# b -[\n",
    "# ...\n",
    "# ]-> c \n",
    "\n",
    "# \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
