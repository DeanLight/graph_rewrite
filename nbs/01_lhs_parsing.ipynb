{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| default_exp lhs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lark\n",
    "# %pip install networkx\n",
    "from lark import Lark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LHS parser ##\n",
    "\n",
    "parsing of the pattern sent as lhs, into a networkX graph representing the template to search.\n",
    "\n",
    "The module converts the declerative constraints regarding the properties of the nodes and edges in the LHS, to imperative functions that are checked together with the 'condition' parameter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#attributes: allow optional \\n here, for imperative syntax)\n",
    "#attribute: #[\"=\" value] \n",
    "\n",
    "#    attr_name: /[a-zA-Z0-9]+/ #TODO: lark-imported\n",
    "#    type:  \"int\" | \"string\" | \"bool\" #TODO: escaped string or word\n",
    "#    value: /[0-9a-zA-Z]/\n",
    "\n",
    "#    %import common.WS #CHANGE to allow \\n in the imperative option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# lhs_parser = Lark(r\"\"\"\n",
    "#     %import common.NUMBER -> NATURAL_NUMBER \n",
    "#     %import common.ESCAPED_STRING\n",
    "#     %import common.WS \n",
    "#     %ignore WS\n",
    "\n",
    "#     NAMED_VERTEX: /[a-zA-Z0-9]+/\n",
    "#     ANONYMUS: \"_\"\n",
    "#     ATTR_NAME: /[a-zA-Z0-9]+/\n",
    "#     TYPE:  \"int\" | \"string\" | \"bool\"\n",
    "#     VALUE: /[0-9a-zA-Z]/\n",
    "\n",
    "#     attribute: ATTR_NAME [\":\" TYPE] [\"=\" VALUE]\n",
    "#     attributes: \"[\" attribute (\",\" attribute)* \"]\"\n",
    "\n",
    "#     multi_connection: \"-\" NATURAL_NUMBER \"+\" [attributes] \"->\" \n",
    "#                     | \"-\" NATURAL_NUMBER [attributes] \"->\" \n",
    "#     connection: \"-\" [attributes \"-\"] \">\"\n",
    "#               | multi_connection\n",
    "    \n",
    "#     index_vertex: NAMED_VERTEX \"<\" NATURAL_NUMBER (\",\" NATURAL_NUMBER)* \">\"\n",
    "\n",
    "#     vertex: NAMED_VERTEX [attributes]\n",
    "#         | index_vertex [attributes]\n",
    "#         | ANONYMUS [attributes]\n",
    "\n",
    "#     pattern: vertex (connection vertex)*\n",
    "#     patterns: pattern (\";\" pattern)*\n",
    "        \n",
    "#     \"\"\", parser=\"lalr\", start='patterns' , debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs_parser = Lark(r\"\"\"\n",
    "    %import common.NUMBER -> NATURAL_NUMBER \n",
    "    %import common.ESCAPED_STRING\n",
    "    %import common.WS \n",
    "    %ignore WS\n",
    "\n",
    "    NAMED_VERTEX: /[a-zA-Z0-9]+/\n",
    "    ANONYMUS: \"_\"\n",
    "    ATTR_NAME: /[a-zA-Z0-9]+/\n",
    "    TYPE:  \"int\" | \"string\" | \"bool\"\n",
    "    VALUE: /[0-9a-zA-Z]/\n",
    "\n",
    "    attribute: ATTR_NAME [\":\" TYPE] [\"=\" VALUE]\n",
    "    attributes: \"[\" attribute (\",\" attribute)* \"]\"\n",
    "\n",
    "    multi_connection: \"-\" NATURAL_NUMBER [attributes] \"->\" \n",
    "    connection: \"-\" [attributes \"-\"] \">\"\n",
    "              | multi_connection\n",
    "    \n",
    "    index_vertex: NAMED_VERTEX \"<\" NATURAL_NUMBER (\",\" NATURAL_NUMBER)* \">\"\n",
    "\n",
    "    vertex: NAMED_VERTEX [attributes]\n",
    "    | index_vertex [attributes]\n",
    "    | ANONYMUS [attributes]\n",
    "\n",
    "    pattern: vertex (connection vertex)*\n",
    "        \n",
    "    \"\"\", parser=\"lalr\", start='pattern' , debug=True)\n",
    "\n",
    "# multi_connection: \"-\" NATURAL_NUMBER \"+\" [attributes] \"->\"  - setting for the \"-num+->\" feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "The transformer is designed to return the networkX graph representing the patterns.\n",
    "\n",
    "For each branch, the appropriate method will be called with the children of the branch as its argument, and its return value will replace the branch in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import itertools\n",
    "import copy\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "cnt:int = 0 # unique id for anonymous vertices\n",
    "from lark import Tree, Transformer\n",
    "class lhsTransformer(Transformer):\n",
    "    def NATURAL_NUMBER(self, number):\n",
    "        return int(number)\n",
    "    \n",
    "    def attribute(self, args): #(attr_name, *rest):\n",
    "        attr_name = args[0]\n",
    "        return (attr_name, \"default\") # constraints are handled in other transformer.\n",
    "    \n",
    "    def attributes(self, attributes): # a list of tuples \n",
    "        # return a packed list of the attribute names.\n",
    "        attr_dict = {}\n",
    "        for attribute in attributes:\n",
    "            # print(attribute)\n",
    "            attr_dict[str(attribute[0])] = attribute[1]\n",
    "        return attr_dict\n",
    "\n",
    "    def multi_connection(self, args): # +\n",
    "        # return the list of attributes(strings), add a special attribute to denote number of duplications.\n",
    "        #   for \"-+->\" implementation also return FALSE if \"+\" is parsed (indicating that the connection is not deterministic)\n",
    "        number, attributes = args\n",
    "        attributes[\"$dup\"] = number\n",
    "        return attributes\n",
    "\n",
    "    # def connection(self, multiconnection_params: tuple): #multiconnection\n",
    "    #     # return the packed list of attributes received, num_duplications, is_deterministic\n",
    "    #     return multiconnection_params\n",
    "\n",
    "    # def connection(self, attributes): # a dict of attributes\n",
    "    #     # return the packed list of attributes received, num_duplications = 1, is_deterministic = True\n",
    "    #     attributes[\"$dup\"] = 1\n",
    "    #     return (attributes, True)\n",
    "\n",
    "    def ANONYMUS(self): #\n",
    "        # return a dedicated name for anonymus (string), and an empty list.\n",
    "        cnt += 1\n",
    "        return (\"$\" + str(cnt), [])\n",
    "\n",
    "    def index_vertex(self, args):\n",
    "        # return the main name of the vertex, and a list of the indices specified.\n",
    "        main_name_tup, *numbers = args #numbers is a list\n",
    "        # print(main_name_tup)\n",
    "        # print(numbers)\n",
    "        return (main_name_tup[0], list(numbers))\n",
    "    \n",
    "    def NAMED_VERTEX(self, name):\n",
    "        # return the main name of the vertex, and an empty list.\n",
    "        return (name, [])\n",
    "\n",
    "    def vertex(self, args): # (vertex_tuple: tuple, attributes: dict = {})\n",
    "        # return arguments\n",
    "        vertex_tuple, *attributes = args # attributes is a empty list/ a list containing a dict\n",
    "        name, indices_list = vertex_tuple \n",
    "        if indices_list == None:\n",
    "            indices_list = []\n",
    "        indices = \",\".join([str(num) for num in indices_list])\n",
    "        new_name = name + \"<\"\n",
    "        new_name = new_name + indices + \">\" # numbers are strings, no convertion needed.\n",
    "        if len(attributes) == 0:\n",
    "            return (new_name, {})\n",
    "        return (new_name, attributes[0])\n",
    "\n",
    "    def pattern(self, args):\n",
    "        # 1) unpack lists of vertices and connections.\n",
    "        vertex, *rest = args\n",
    "        conn, vertices = list(rest)[::2], list(rest)[1::2]\n",
    "        vertices.insert(0,vertex)\n",
    "        print(vertices)\n",
    "        print(conn)\n",
    "        # 2) create a networkX graph:\n",
    "            # if there is a special attribute with TRUE, dumplicate the connection __number__ times.\n",
    "        G = nx.DiGraph()\n",
    "\n",
    "        # simplified vertion - ignore duplications\n",
    "        G.add_nodes_from(vertices)\n",
    "        edge_list = []\n",
    "        for i,edge in enumerate(conn):\n",
    "            edge_list.append((vertices[i], vertices[i+1], edge[0])) # ignore edge[1] - determinism flag. edge[0] is attributes.\n",
    "\n",
    "        # more complex vertion - duplications\n",
    "        # create a recursive function that adds the vertices and edges, \n",
    "        # that calls itself by the number of duplications on each level.\n",
    "        G.add_edges_from(edge_list)\n",
    "        return G\n",
    "\n",
    "    # def patterns(self, g, *graphs):\n",
    "    #     patterns = list(graphs)\n",
    "    #     patterns.insert(0,g)\n",
    "    #     # unite all the patterns into a single graph\n",
    "    #     G = nx.DiGraph()\n",
    "\n",
    "    #     combined_attributes = dict() # dict of dicts (node_name -> attribute -> value)\n",
    "    #     new_nodes = []\n",
    "    #     new_edges = []\n",
    "    #     for graph in patterns:\n",
    "    #         for node in graph.nodes:\n",
    "    #             combined_attributes[node] = combined_attributes[node] | graph.nodes.data()[node]\n",
    "    #             new_nodes.append(node) #unite the dicts for each\n",
    "    #         for edge in graph.edges:\n",
    "    #             combined_attributes[edge[0]+\",\"+edge[1]] = combined_attributes[edge[0]+\",\"+edge[1]] | graph.edges[edge[0],edge[1]]\n",
    "    #             new_edges.append(edge)\n",
    "\n",
    "    #     G.add_nodes_from([(node, combined_attributes[node]) for node in new_nodes])\n",
    "    #     G.add_edges_from([(node1, node2, combined_attributes[node1+\",\"+node2]) for (node1,node2) in new_edges])\n",
    "    #     return G"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type and constant value checking\n",
    "The transformer is designed to collect the node type and constant node value constraints, such that they are added to the 'condition' parameter to be checked later.\n",
    "\n",
    "This transformer works on a copy of the tree to keep it intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class collectTypeConstraints(Transformer):\n",
    "    def attribute(self, attr_name, type, value):\n",
    "        # return a mapping from attr_name - > required type and value\n",
    "        pass\n",
    "\n",
    "    def attributes(self, *attributes):\n",
    "        # return a packed list of the attribute mappings.\n",
    "        pass\n",
    "\n",
    "    def vertex(self, name, indices_list, attributes_list):\n",
    "        # same as lhsTransformer\n",
    "        pass\n",
    "\n",
    "    def pattern(self, vertex, *connections_to_vertex):\n",
    "        # return arguments\n",
    "        pass\n",
    "\n",
    "    def patterns(self, *patterns):\n",
    "        # unpack lists of vertices and connections.\n",
    "        def typeCondition(Match):\n",
    "            # for every vertex in vertex list:\n",
    "                # create full_vertex_name by the attached indices list\n",
    "                # for every attr, type, name required for the vertex:\n",
    "                    # constructor = getName(type) - get the constructor for the type\n",
    "                    # 1) check that the required type and value match together.\n",
    "                    # try:\n",
    "                    #     instance = constructor(value)\n",
    "                    # Except:\n",
    "                        # flag = False: value does not match the type.\n",
    "\n",
    "                    # 2) check that the value constraint holds\n",
    "                    # if getattr(instance, __eq__) == None:\n",
    "                        # flag = False. the type must implement __eq__\n",
    "                    # if not (instance == match[full_vertex_name][attr])\n",
    "\n",
    "                    # no need to check the type constraint(?), if the value fits. (python)\n",
    "\n",
    "            # TODO: perform the same iterations in the connections list.\n",
    "\n",
    "            #return flag and condition(Match)\n",
    "            pass\n",
    "\n",
    "        return typeCondition #sent as a module output and replaces condition.\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lhs_to_graph(lhs):\n",
    "    tree = lhs_parser.parse(lhs)\n",
    "    final_g = lhsTransformer().transform(tree) #networkx graph\n",
    "    return final_g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grammar Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree = lhs_parser.parse(\"aaaaa->b\") #.pretty(indent_str = \" $ \")\n",
    "# assert(tree != None)\n",
    "# assert(tree)\n",
    "# assert(tree == \n",
    "#     Tree(Token('RULE', 'patterns'),[\n",
    "#       Tree(Token('RULE', 'pattern'),[\n",
    "#         Tree(Token('RULE', 'vertex'),[\n",
    "#           Tree(Token('RULE', 'vertex'),[]),\n",
    "#           None\n",
    "#         ])\n",
    "#       ])\n",
    "#     ]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(nodes, edges=[]):\n",
    "    g = nx.DiGraph()\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges)\n",
    "    return g\n",
    "\n",
    "def graphs_equal(graph1, graph2):  \n",
    "    return (\n",
    "        graph1.adj == graph2.adj\n",
    "        and graph1.nodes == graph2.nodes\n",
    "        and graph1.edges == graph2.edges #added\n",
    "        and graph1.graph == graph2.graph \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a<1,2>', {'x': 'default', 'y': 'default'})]\n",
      "[]\n",
      "['a<1,2>']\n",
      "[('a<1,2>', {'x': 'default', 'y': 'default'})]\n",
      "[]\n",
      "------\n",
      "['a<1,2>']\n",
      "[('a<1,2>', {'x': 'default', 'y': 'default'})]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s = \"a<1,2>[x=5, y: int = 6]\"\n",
    "res = lhs_to_graph(s)\n",
    "expected = create_graph(['a<1,2>'])\n",
    "expected.nodes[\"a<1,2>\"][\"x\"] = \"default\"\n",
    "expected.nodes[\"a<1,2>\"][\"y\"] = \"default\"\n",
    "\n",
    "print(res.nodes)\n",
    "print(res.nodes.data())\n",
    "print(res.edges)\n",
    "print(\"------\")\n",
    "print(expected.nodes)\n",
    "print(expected.nodes.data())\n",
    "print(expected.edges)\n",
    "\n",
    "assert(graphs_equal(res,expected))\n",
    "\n",
    "\n",
    "\n",
    "# graph1 = lhs_to_graph(\"a[a]\")\n",
    "# expected = create_graph([\"a\",\"b\"],[(\"a\",\"b\")])\n",
    "# assert graphs_equal(graph1, expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_syntax =  \"\"\"\n",
    "a -> b\n",
    "\n",
    "a -[x:int = ...]-> b\n",
    "\n",
    "a -> b[x:int = ...]\n",
    "\n",
    "a -> b -6+[weight:int]-> c -> d[value:int]\n",
    "d<0> -> e\n",
    "d<5> -> e\n",
    "\n",
    "b -+-> d[value:int]\n",
    "d<0> -7-> e\n",
    "e<0,5> -> _\n",
    "\n",
    "b[ \\\n",
    "value: str = \\\"hello\\\", \\\n",
    "id: int \\\n",
    "]\n",
    "\n",
    "b -[\n",
    "...\n",
    "]-> c \n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
