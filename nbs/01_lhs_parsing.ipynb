{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lark import Lark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LHS parser ##\n",
    "\n",
    "parsing of the pattern sent as lhs, into a networkX graph representing the template to search.\n",
    "\n",
    "The module converts the declerative constraints regarding the properties of the nodes and edges in the LHS, to imperative functions that are checked together with the 'condition' parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "GrammarError",
     "evalue": "Unexpected input at line 10 column 34 in <string>: \n\n    named_vertex: /[a-zA-Z0-9]*/ #any string with numbers and letters onl\n                                 ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedCharacters\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/load_grammar.py:961\u001b[0m, in \u001b[0;36m_parse_grammar\u001b[0;34m(text, name, start)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 961\u001b[0m     tree \u001b[39m=\u001b[39m _get_parser()\u001b[39m.\u001b[39;49mparse(text \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m, start)\n\u001b[1;32m    962\u001b[0m \u001b[39mexcept\u001b[39;00m UnexpectedCharacters \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/parser_frontends.py:96\u001b[0m, in \u001b[0;36mParsingFrontend.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m     95\u001b[0m stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_lexer_thread(text)\n\u001b[0;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparser\u001b[39m.\u001b[39;49mparse(stream, chosen_start, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/parsers/lalr_parser.py:41\u001b[0m, in \u001b[0;36mLALR_Parser.parse\u001b[0;34m(self, lexer, start, on_error)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparser\u001b[39m.\u001b[39;49mparse(lexer, start)\n\u001b[1;32m     42\u001b[0m \u001b[39mexcept\u001b[39;00m UnexpectedInput \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/parsers/lalr_parser.py:171\u001b[0m, in \u001b[0;36m_Parser.parse\u001b[0;34m(self, lexer, start, value_stack, state_stack, start_interactive)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[39mreturn\u001b[39;00m InteractiveParser(\u001b[39mself\u001b[39m, parser_state, parser_state\u001b[39m.\u001b[39mlexer)\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_from_state(parser_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/parsers/lalr_parser.py:193\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state, last_token)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    194\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/parsers/lalr_parser.py:183\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state, last_token)\u001b[0m\n\u001b[1;32m    182\u001b[0m token \u001b[39m=\u001b[39m last_token\n\u001b[0;32m--> 183\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m state\u001b[39m.\u001b[39mlexer\u001b[39m.\u001b[39mlex(state):\n\u001b[1;32m    184\u001b[0m     state\u001b[39m.\u001b[39mfeed_token(token)\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/lexer.py:518\u001b[0m, in \u001b[0;36mBasicLexer.lex\u001b[0;34m(self, state, parser_state)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext_token(state, parser_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/lexer.py:528\u001b[0m, in \u001b[0;36mBasicLexer.next_token\u001b[0;34m(self, lex_state, parser_state)\u001b[0m\n\u001b[1;32m    527\u001b[0m         allowed \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39m<END-OF-FILE>\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m--> 528\u001b[0m     \u001b[39mraise\u001b[39;00m UnexpectedCharacters(lex_state\u001b[39m.\u001b[39mtext, line_ctr\u001b[39m.\u001b[39mchar_pos, line_ctr\u001b[39m.\u001b[39mline, line_ctr\u001b[39m.\u001b[39mcolumn,\n\u001b[1;32m    529\u001b[0m                                allowed\u001b[39m=\u001b[39mallowed, token_history\u001b[39m=\u001b[39mlex_state\u001b[39m.\u001b[39mlast_token \u001b[39mand\u001b[39;00m [lex_state\u001b[39m.\u001b[39mlast_token],\n\u001b[1;32m    530\u001b[0m                                state\u001b[39m=\u001b[39mparser_state, terminals_by_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mterminals_by_name)\n\u001b[1;32m    532\u001b[0m value, type_ \u001b[39m=\u001b[39m res\n",
      "\u001b[0;31mUnexpectedCharacters\u001b[0m: No terminal matches '#' in the current parser context, at line 10 col 34\n\n    named_vertex: /[a-zA-Z0-9]*/ #any string with numbers and letters onl\n                                 ^\nExpected one of: \n\t* _LPAR\n\t* _TO\n\t* RULE\n\t* _RBRA\n\t* _OR\n\t* _IGNORE\n\t* _OVERRIDE\n\t* _DOT\n\t* STRING\n\t* _DOTDOT\n\t* _LBRA\n\t* _RBRACE\n\t* OP\n\t* _NL_OR\n\t* TERMINAL\n\t* _DECLARE\n\t* NUMBER\n\t* _IMPORT\n\t* REGEXP\n\t* _EXTEND\n\t* RULE_MODIFIERS\n\t* _RPAR\n\t* _NL\n\t* TILDE\n\t* _COLON\n\t* _LBRACE\n\t* _COMMA\n\nPrevious tokens: Token('REGEXP', '/[a-zA-Z0-9]*/')\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGrammarError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lhs_parser \u001b[39m=\u001b[39m Lark(\u001b[39mr\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[39m    patterns: pattern (\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m pattern)*\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[39m            \u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[39m    pattern: [vertex (connection vertex)*]\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[39m    vertex: named_vertex attributes\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[39m          | index_vertex attributes\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[39m          | ANONYMUS attributes\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[39m    named_vertex: /[a-zA-Z0-9]*/ #any string with numbers and letters only\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[39m    index_vertex: named_vertex \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m<\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m NATURAL_NUMBER (\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m NATURAL_NUMBER)* \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[39m    ANONYMUS: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[39m    connection: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m [attributes \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m] \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[39m              | multi_connection\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39m    attributes: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m[\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m attribute (, #allow optional \u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mn here, for imperative syntax)\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[39m                              attribute)* \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[39m    multi_connection: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m NATURAL_NUMBER \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m [attributes \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m] \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m->\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m # explicit minimal constraint\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[39m                    | \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m NATURAL_NUMBER [attributes \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m] \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m->\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m # deterministic number of connections\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[39m    attribute: attr_name [\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m:\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m type] [\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m value] \u001b[39;49m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[39m    attr_name: #lark-imported\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[39m    type: #lark-imported #escaped string or word\u001b[39;49m\n\u001b[1;32m     27\u001b[0m \u001b[39m    value: #imported?\u001b[39;49m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    NATURAL_NUMBER: #imported?\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m%i\u001b[39;49;00m\u001b[39mmport common.ESCAPED_STRING\u001b[39;49m\n\u001b[1;32m     32\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m%i\u001b[39;49;00m\u001b[39mmport common.WS #CHANGE to allow \u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mn in the imperative option.\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m%i\u001b[39;49;00m\u001b[39mgnore WS\u001b[39;49m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m, start\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpatterns\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/lark.py:349\u001b[0m, in \u001b[0;36mLark.__init__\u001b[0;34m(self, grammar, **options)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions \u001b[39m=\u001b[39m old_options\n\u001b[1;32m    348\u001b[0m     \u001b[39m# Parse the grammar file and compose the grammars\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrammar, used_files \u001b[39m=\u001b[39m load_grammar(grammar, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mimport_paths, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mkeep_all_tokens)\n\u001b[1;32m    350\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(grammar, Grammar)\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/load_grammar.py:1410\u001b[0m, in \u001b[0;36mload_grammar\u001b[0;34m(grammar, source, import_paths, global_keep_all_tokens)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_grammar\u001b[39m(grammar, source, import_paths, global_keep_all_tokens):\n\u001b[1;32m   1409\u001b[0m     builder \u001b[39m=\u001b[39m GrammarBuilder(global_keep_all_tokens, import_paths)\n\u001b[0;32m-> 1410\u001b[0m     builder\u001b[39m.\u001b[39;49mload_grammar(grammar, source)\n\u001b[1;32m   1411\u001b[0m     \u001b[39mreturn\u001b[39;00m builder\u001b[39m.\u001b[39mbuild(), builder\u001b[39m.\u001b[39mused_files\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/load_grammar.py:1235\u001b[0m, in \u001b[0;36mGrammarBuilder.load_grammar\u001b[0;34m(self, grammar_text, grammar_name, mangle)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_grammar\u001b[39m(\u001b[39mself\u001b[39m, grammar_text: \u001b[39mstr\u001b[39m, grammar_name: \u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<?>\u001b[39m\u001b[39m\"\u001b[39m, mangle: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mstr\u001b[39m]]\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1235\u001b[0m     tree \u001b[39m=\u001b[39m _parse_grammar(grammar_text, grammar_name)\n\u001b[1;32m   1237\u001b[0m     imports: Dict[Tuple[\u001b[39mstr\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m], Tuple[Optional[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]] \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1239\u001b[0m     \u001b[39mfor\u001b[39;00m stmt \u001b[39min\u001b[39;00m tree\u001b[39m.\u001b[39mchildren:\n",
      "File \u001b[0;32m~/miniconda3/envs/geom2/lib/python3.9/site-packages/lark/load_grammar.py:964\u001b[0m, in \u001b[0;36m_parse_grammar\u001b[0;34m(text, name, start)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mexcept\u001b[39;00m UnexpectedCharacters \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    963\u001b[0m     context \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mget_context(text)\n\u001b[0;32m--> 964\u001b[0m     \u001b[39mraise\u001b[39;00m GrammarError(\u001b[39m\"\u001b[39m\u001b[39mUnexpected input at line \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m column \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    965\u001b[0m                        (e\u001b[39m.\u001b[39mline, e\u001b[39m.\u001b[39mcolumn, name, context))\n\u001b[1;32m    966\u001b[0m \u001b[39mexcept\u001b[39;00m UnexpectedToken \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    967\u001b[0m     context \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mget_context(text)\n",
      "\u001b[0;31mGrammarError\u001b[0m: Unexpected input at line 10 column 34 in <string>: \n\n    named_vertex: /[a-zA-Z0-9]*/ #any string with numbers and letters onl\n                                 ^\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lhs_parser = Lark(r\"\"\"\n",
    "    patterns: pattern (\";\" pattern)*\n",
    "            \n",
    "    pattern: [vertex (connection vertex)*]\n",
    "\n",
    "    vertex: named_vertex attributes\n",
    "          | index_vertex attributes\n",
    "          | ANONYMUS attributes\n",
    "\n",
    "    named_vertex: [a-zA-Z0-9]* #any string with numbers and letters only\n",
    "    index_vertex: named_vertex \"<\" NATURAL_NUMBER (\",\" NATURAL_NUMBER)* \">\"\n",
    "    ANONYMUS: \"_\"\n",
    "\n",
    "    connection: \"-\" [attributes \"-\"] \">\"\n",
    "              | multi_connection\n",
    "\n",
    "    attributes: \"\\[\" attribute (, #allow optional \\n here, for imperative syntax)\n",
    "                              attribute)* \"\\]\"\n",
    "\n",
    "    multi_connection: \"-\" NATURAL_NUMBER \"+\" [attributes \"-\"] \"->\" # explicit minimal constraint\n",
    "                    | \"-\" NATURAL_NUMBER [attributes \"-\"] \"->\" # deterministic number of connections\n",
    "\n",
    "    attribute: attr_name [\":\" type] [\"=\" value] \n",
    "\n",
    "    attr_name: #lark-imported\n",
    "    type: #lark-imported #escaped string or word\n",
    "    value: #imported?\n",
    "\n",
    "    NATURAL_NUMBER: #imported?\n",
    "\n",
    "    %import common.ESCAPED_STRING\n",
    "    %import common.WS #CHANGE to allow \\n in the imperative option.\n",
    "    %ignore WS\n",
    "\n",
    "    \"\"\", start='patterns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "The transformer is designed to return the networkX graph representing the patterns.\n",
    "\n",
    "For each branch, the appropriate method will be called with the children of the branch as its argument, and its return value will replace the branch in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lark import Transformer\n",
    "class lhsTransformer(Transformer):\n",
    "    def attribute(self, attr_name, type, value):\n",
    "        # return attr_name, constraints are handled in other transformer.\n",
    "        pass\n",
    "\n",
    "    def multi_connection(self, number, attributes): # +\n",
    "        # return the list of attributes(strings), number of duplications,\n",
    "        #   and FALSE (indicating that the connection is not deterministic)\n",
    "\n",
    "        # renewed: return the list of attributes(strings), add a special attribute to denote number of duplications,\n",
    "        #   and FALSE (indicating that the connection is not deterministic)\n",
    "        pass\n",
    "    def multi_connection(self, number, attributes ): # no +\n",
    "        # return the list of attributes(strings), number of duplications,\n",
    "        #  and TRUE (indicating that the connection is deterministic)\n",
    "\n",
    "        # renewed: return the list of attributes(strings), add a special attribute to denote number of duplications,\n",
    "        #   and TRUE (indicating that the connection is not deterministic)\n",
    "        pass\n",
    "\n",
    "    def attributes(self, *attributes):\n",
    "        # return a packed list of the attribute names.\n",
    "        pass\n",
    "\n",
    "    def connection(self, attributes_list, num_duplications, is_deterministic): #multiconnection\n",
    "        # return the packed list of attributes received, num_duplications, is_deterministic\n",
    "        pass\n",
    "\n",
    "    def connection(self, attributes): #\n",
    "        # return the packed list of attributes received, num_duplications = 1, is_deterministic = True\n",
    "        pass\n",
    "\n",
    "    def ANONYMUS(self): #\n",
    "        # return a dedicated name for anonymus (string), and an empty list.\n",
    "        pass\n",
    "\n",
    "    def sub_vertex(self, main_name, *numbers):\n",
    "        # return the main name of the vertex, and a list of the indices specified.\n",
    "        pass\n",
    "    \n",
    "    def named_vertex(self, __):\n",
    "        # return the main name of the vertex, and an empty list.\n",
    "        pass\n",
    "\n",
    "    def vertex(self, name, indices_list, attributes_list):\n",
    "        # return arguments\n",
    "        pass\n",
    "\n",
    "    def pattern(self, vertex, *connections_to_vertex):\n",
    "        # 1) unpack lists of vertices and connections.\n",
    "        # 2) create a networkX graph:\n",
    "            # if there is a special attribute with TRUE, dumplicate the connection __number__ times.\n",
    "\n",
    "        pass\n",
    "\n",
    "    def patterns(self,):\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type and constant value checking\n",
    "The transformer is designed to collect the node type and constant node value constraints, such that they are added to the 'condition' parameter to be checked later.\n",
    "\n",
    "This transformer works on a copy of the tree to keep it intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class collectTypeConstraints(Transformer):\n",
    "    def attribute(self, attr_name, type, value):\n",
    "        # return a mapping from attr_name - > required type and value\n",
    "        pass\n",
    "\n",
    "    def attributes(self, *attributes):\n",
    "        # return a packed list of the attribute mappings.\n",
    "        pass\n",
    "\n",
    "    def vertex(self, name, indices_list, attributes_list):\n",
    "        # same as lhsTransformer\n",
    "        pass\n",
    "\n",
    "    def pattern(self, vertex, *connections_to_vertex):\n",
    "        # return arguments\n",
    "        pass\n",
    "\n",
    "    def patterns(self, *patterns):\n",
    "        # unpack lists of vertices and connections.\n",
    "        def typeCondition(Match):\n",
    "            # for every vertex in vertex list:\n",
    "                # create full_vertex_name by the attached indices list\n",
    "                # for every attr, type, name required for the vertex:\n",
    "                    # constructor = getName(type) - get the constructor for the type\n",
    "                    # 1) check that the required type and value match together.\n",
    "                    # try:\n",
    "                    #     instance = constructor(value)\n",
    "                    # Except:\n",
    "                        # flag = False: value does not match the type.\n",
    "\n",
    "                    # 2) check that the value constraint holds\n",
    "                    # if getattr(instance, __eq__) == None:\n",
    "                        # flag = False. the type must implement __eq__\n",
    "                    # if not (instance == match[full_vertex_name][attr])\n",
    "\n",
    "                    # no need to check the type constraint(?), if the value fits. (python)\n",
    "\n",
    "            # TODO: perform the same iterations in the connections list.\n",
    "\n",
    "            #return flag and condition(Match)\n",
    "            pass\n",
    "\n",
    "        return typeCondition #sent as a module output and replaces condition.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_syntax =  \"\"\"\n",
    "a -> b\n",
    "\n",
    "a -[x:int = ...]-> b\n",
    "\n",
    "a -> b[x:int = ...]\n",
    "\n",
    "a -> b -6+[weight:int]-> c -> d[value:int]\n",
    "d<0> -> e\n",
    "d<5> -> e\n",
    "\n",
    "b -+-> d[value:int]\n",
    "d<0> -7-> e\n",
    "e<0,5> -> _\n",
    "\n",
    "b[ \\\n",
    "value: str = \\\"hello\\\", \\\n",
    "id: int \\\n",
    "]\n",
    "\n",
    "b -[\n",
    "...\n",
    "]-> c \n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
